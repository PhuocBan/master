{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Copy of 25/10 Tong hop.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ceZ9AZyTWQiY"
      },
      "source": [
        "# 1. Tạo tập test cho công cụ sửa lỗi chính tả"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9FTCCyya_H98"
      },
      "source": [
        "Tạo tập badword"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rsg4GZ-f7vWw"
      },
      "source": [
        "import pickle\n",
        "def load(path):\n",
        "  return pickle.load(open(path, 'rb'))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-gkmGqiP_Hih"
      },
      "source": [
        "# load dữ liệu lên\n",
        "train_x = load('/content/drive/My Drive/Colab Notebooks/dump_hatespeech/train_x.dump')\n",
        "train_y = load('/content/drive/My Drive/Colab Notebooks/dump_hatespeech/train_y.dump')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SU_r427rCCV3"
      },
      "source": [
        "# tách các bình luận thuộc các lớp ra\n",
        "clean = []\n",
        "hate_offensive = []\n",
        "train_x = list(train_x)\n",
        "for i in range(len(train_y)):\n",
        "  if train_y[i,0] == 1:\n",
        "    clean.append(train_x[i].replace('_', ' '))\n",
        "  else:\n",
        "    hate_offensive.append(train_x[i].replace('_', ' '))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tQcmu6a_C5ht",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3178016a-5b93-4d94-d86d-a29af4af256c"
      },
      "source": [
        "print(\"clean lenght                \", len(clean))\n",
        "print(\"hate and offensive lenght   \", len(hate_offensive))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "clean lenght                 14901\n",
            "hate and offensive lenght    1375\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ub7ssxaILddu"
      },
      "source": [
        "# chuyển các câu về dạng vector tần suất xuất hiện\n",
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "vectorizer = CountVectorizer(min_df=8).fit(clean+hate_offensive*4)\n",
        "\n",
        "clean_vec = vectorizer.transform(clean).toarray()\n",
        "hate_offensive_vec = vectorizer.transform(hate_offensive).toarray()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0_Qv45SzNCmH"
      },
      "source": [
        "import numpy as np\n",
        "# tính tổng tần suất của lớp clean và hate_offensive\n",
        "clean_vec = np.sum(clean_vec, axis=0)\n",
        "hate_offensive_vec = np.sum(hate_offensive_vec, axis=0)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IUC1OykyPNEE",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ca7403a9-4954-4aa4-dd9b-8dd54f90dcdd"
      },
      "source": [
        "clean_vec"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([13,  9,  6, ..., 19, 10, 79])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hiKUzc4MPPN2",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "cedcc355-b559-4358-8da3-00d51a948c32"
      },
      "source": [
        "hate_offensive_vec"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([0, 0, 1, ..., 0, 3, 1])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "04anitdKOo2g"
      },
      "source": [
        "# lấy tần suất của lớp hate_ofensive trừ tần suất của lớp clean để tìm ra những từ độc hại (xuất hiện nhiều trong hate_offensive và ít xuất hiện trong clean)\r\n",
        "sub = np.subtract(hate_offensive_vec, clean_vec)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XZHZmsxMS3OG"
      },
      "source": [
        "feature = vectorizer.get_feature_names()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DNnkRxDCO7v0"
      },
      "source": [
        "# Lấy ra những từ badword\n",
        "badwords = []\n",
        "feature = vectorizer.get_feature_names()\n",
        "for i in range(len(sub)):\n",
        "  if sub[i] > 2:\n",
        "    badwords.append(feature[i])\n",
        "print(\"badwords lenght\", len(badwords))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "k8BQsUPsQBNk",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c5f62bee-e1de-4d40-9901-ed8bb0580de6"
      },
      "source": [
        "badwords"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['bọn',\n",
              " 'cc',\n",
              " 'chó',\n",
              " 'chịch',\n",
              " 'chửi',\n",
              " 'cút',\n",
              " 'cứt',\n",
              " 'dcm',\n",
              " 'dm',\n",
              " 'hãm',\n",
              " 'lol',\n",
              " 'lũ',\n",
              " 'lồn',\n",
              " 'mày',\n",
              " 'mầy',\n",
              " 'mồm',\n",
              " 'ngu',\n",
              " 'nhục',\n",
              " 'sủa',\n",
              " 'thằng',\n",
              " 'tởm',\n",
              " 'éo',\n",
              " 'óc',\n",
              " 'đcm',\n",
              " 'đm',\n",
              " 'đéo',\n",
              " 'đĩ',\n",
              " 'địt',\n",
              " 'đụ']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9yGhEtMtfbPq"
      },
      "source": [
        "Thống kê tần suất của các từ badword và sort chúng lại"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aog4o_VJfamr"
      },
      "source": [
        "from collections import Counter"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VL1wn8YLPlHo"
      },
      "source": [
        "count = Counter((' '.join(hate_offensive)).split())"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3EjCvErWf2Wm"
      },
      "source": [
        "temp = dict()\n",
        "for i in badwords:\n",
        "  temp[i] = count[i]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7AFgFB4YgEYR"
      },
      "source": [
        "badwords = temp"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2SvXlbMggE0F"
      },
      "source": [
        "badwords = sorted(badwords.items(), key=lambda x: x[1], reverse=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IFoVMPY7-fGL"
      },
      "source": [
        "bws = badwords[:]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ANzDEEe9gnwS"
      },
      "source": [
        "s = ''\n",
        "badwords = dict(badwords)\n",
        "for i in badwords:\n",
        "  s = s + i + ' ' + str(badwords[i]) + '\\n'\n",
        "s = s[:-1]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "p2jMPHSRhMP7",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c4612ba7-a71a-43c9-d95d-d02810489a3f"
      },
      "source": [
        "# ghi tập badword xuống\r\n",
        "open('/content/drive/My Drive/Colab Notebooks/KLTN_hatespeech/SuaLoiChinhTa/badwords.txt', 'w').write(s)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "421"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "i2xuK-hIifWn"
      },
      "source": [
        "Đọc tập dữ liệu thực tế và tìm các lỗi chính tả của các từ badword"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AnCxH5nliZ8K"
      },
      "source": [
        "thin_data = open('/content/drive/My Drive/Colab Notebooks/BadWord/data_processed.txt').read().replace('\\n', ' ')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SZOI6YmkmLLc"
      },
      "source": [
        "thin_count = Counter(thin_data.split())"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZTAoDs9TnTnV"
      },
      "source": [
        "misspell = dict()\n",
        "for i in thin_count:\n",
        "  if thin_count[i] < 5:\n",
        "    misspell[i] = thin_count[i]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rMOVdWhboGZp",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b0b917b6-0a09-4660-e27f-782d6b7ecda8"
      },
      "source": [
        "!pip install editdistance\n",
        "from editdistance import eval as dist\n",
        "misspell_badwords = []\n",
        "for i in badwords:\n",
        "  temp = dict()\n",
        "  for j in misspell:\n",
        "    if dist(i, j) <= 2:\n",
        "      temp[j] = thin_count[j]\n",
        "      temp = sorted(temp.items(), key=lambda x: x[1], reverse=True)\n",
        "      temp = dict(temp)\n",
        "  misspell_badwords.append(temp)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: editdistance in /usr/local/lib/python3.6/dist-packages (0.5.3)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "x7sG04O0pg81",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "d086f134-bea1-4469-9c34-4c718b580304"
      },
      "source": [
        "s = ''\n",
        "for i in range(len(badwords)):\n",
        "  try:\n",
        "    s = s + list(badwords)[i] + '\\t' + ' '.join(misspell_badwords[i]) + '\\n'\n",
        "  except:\n",
        "    s = s + list(badwords)[i] + '\\n'\n",
        "s = s[:-1]\n",
        "open('/content/drive/My Drive/Colab Notebooks/KLTN_hatespeech/SuaLoiChinhTa/auto_misspell_badwords.txt','w').write(s)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "285974"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 119
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AkL9l_obMFjf"
      },
      "source": [
        "Check lại tập badword sai chính tả đã chỉnh sửa thủ công"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rexe2yEuLr_w"
      },
      "source": [
        "mb_edited = open('/content/drive/My Drive/Colab Notebooks/KLTN_hatespeech/SuaLoiChinhTa/misspell_badwords_edited.txt').read().split('\\n')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5EKh8IfQUwVu"
      },
      "source": [
        "vocab = open('/content/drive/My Drive/Colab Notebooks/KLTN_hatespeech/vocab.txt').read().split('\\n')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "08bZNZEYQ4Jj"
      },
      "source": [
        "badwords = []\n",
        "misspells = []\n",
        "all_misspells = []\n",
        "for i in mb_edited:\n",
        "  bw, mss = i.strip().split('\\t')\n",
        "  if bw in dict(bws):\n",
        "    temp = mss.split(' ')\n",
        "    mss = []\n",
        "    for j in temp:\n",
        "      if j not in vocab:\n",
        "        mss.append(j)\n",
        "    badwords.append(bw)\n",
        "    misspells.append(mss)\n",
        "    all_misspells += mss"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "J4wpTxWa9fMp",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8b9873da-3c5b-4bdc-bc85-eef91c444a89"
      },
      "source": [
        "len(badwords)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "25"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 35
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DURPHScAroJZ"
      },
      "source": [
        "Tạo lỗi chính tả cho tập test"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wBCqDATZRRdr"
      },
      "source": [
        "import pandas as pd\n",
        "orig_hate      = pd.read_csv('/content/drive/My Drive/Colab Notebooks/KLTN_hatespeech/hate_and_offensive_orig_test/orig_hate.csv')\n",
        "orig_offensive = pd.read_csv('/content/drive/My Drive/Colab Notebooks/KLTN_hatespeech/hate_and_offensive_orig_test/orig_offensive.csv')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Dj1FUtCnrsFr"
      },
      "source": [
        "def read_static(path):\n",
        "  data = open(path).read().split('\\n')\n",
        "  result = dict()\n",
        "  for i in data:\n",
        "    try:\n",
        "      word, freq = i.split()\n",
        "      freq = int(freq)\n",
        "      if freq >2:\n",
        "        result[word] = freq\n",
        "    except:\n",
        "      None\n",
        "  return result \n",
        "\n",
        "hate_word_static      = read_static('/content/drive/My Drive/Colab Notebooks/KLTN_hatespeech/temp/word_statistics/hate_words.txt')\n",
        "offensive_word_static = read_static('/content/drive/My Drive/Colab Notebooks/KLTN_hatespeech/temp/word_statistics/offensive_words.txt')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IBuYv3Uwvp2s",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "41275a63-b245-4226-e551-3cb77055bbd2"
      },
      "source": [
        "hate_offensive_cmts = list(orig_hate['comment']) + list(orig_offensive['comment'])\n",
        "print('hate comment lenght       ', len(list(orig_hate['comment'])))\n",
        "print('offensive comment lenght  ', len(list(orig_offensive['comment'])))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "hate comment lenght        152\n",
            "offensive comment lenght   204\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WZYwSVdN0GWl"
      },
      "source": [
        "import string\n",
        "import random\n",
        "def change_a_word_dis1(word):\n",
        "    Alphabet_List = list(string.ascii_lowercase)\n",
        "    # Alphabet_List.append(' ')\n",
        "    \n",
        "    # 0 - add\n",
        "    # 1 - delete\n",
        "    # 2 - change    \n",
        "    if len(word) <4:\n",
        "      method = random.choice([0,2])\n",
        "    else:\n",
        "      method = random.randint(0, 2)\n",
        "    \n",
        "    if (method==0):\n",
        "        pos = random.randint(0, len(word))\n",
        "        word1 = word[0:pos]\n",
        "        word2 = word[pos:len(word)]\n",
        "        add = Alphabet_List[random.randint(0, len(Alphabet_List)-1)]\n",
        "        return word1+add+word2\n",
        "        \n",
        "    elif (method==1):\n",
        "        pos = random.randint(0, len(word)-1)\n",
        "        word1 = word[0:pos]\n",
        "        word2 = word[pos+1:len(word)]\n",
        "        return word1+word2\n",
        "        \n",
        "    elif (method==2):\n",
        "        pos = random.randint(0, len(word)-1)\n",
        "        word1 = word[0:pos]\n",
        "        word2 = word[pos+1:len(word)]\n",
        "        change = word[pos]\n",
        "        while (change==word[pos]):        \n",
        "            change = Alphabet_List[random.randint(0, len(Alphabet_List)-1)]\n",
        "        return word1+change+word2\n",
        "\n",
        "def change_a_word(word):\n",
        "  if len(word) < 5:\n",
        "    return change_a_word_dis1(word)\n",
        "  else:\n",
        "    if random.choice([False, True]):\n",
        "      return change_a_word_dis1(word)\n",
        "    else:\n",
        "      return change_a_word_dis1(change_a_word_dis1(word))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1hCjDByhpv4F"
      },
      "source": [
        "import random\n",
        "# tạo lỗi chính tả cho tập badword\n",
        "correct_words = []\n",
        "wrong_words   = []\n",
        "wrong_hate_offensive_cmts = []\n",
        "wrong_type = [] # 0: Lỗi thực tế, 1: Lỗi được thu thập từ bộ anh thìn, 2: Lỗi tự sinh\n",
        "n = 0\n",
        "for id, i in enumerate(hate_offensive_cmts):\n",
        "  i = i.split()\n",
        "  flag = False\n",
        "  for id2, j in enumerate(i):\n",
        "    # Nếu lỗi chính tả độc hại có sẵn trong trong bình luận\n",
        "    if j in all_misspells:\n",
        "      # tìm xem từ gốc của nó là từ nào\n",
        "      for z in range(len(misspells)):\n",
        "        if j in misspells[z]:\n",
        "          correct_words.append(badwords[z])\n",
        "          wrong_words.append(j)\n",
        "          wrong_hate_offensive_cmts.append(' '.join(i))\n",
        "          wrong_type.append(0)\n",
        "          flag = True\n",
        "          break\n",
        "    if flag:\n",
        "        break\n",
        "  if flag:\n",
        "    continue\n",
        "\n",
        "  for id2, j in enumerate(i):\n",
        "    # Nếu câu có chứa từ badword:\n",
        "    if j in badwords:\n",
        "      index = badwords.index(j)\n",
        "      correct_words.append(badwords[index])\n",
        "      wr_w = random.choice(misspells[index])\n",
        "      wrong_words.append(wr_w)\n",
        "      i[id2] = wr_w\n",
        "      wrong_hate_offensive_cmts.append(' '.join(i))\n",
        "      wrong_type.append(1)\n",
        "      flag = True\n",
        "      break\n",
        "  if flag:\n",
        "    continue\n",
        "\n",
        "    # Nếu câu không chứa từ badword thì thêm tự động vào \n",
        "         \n",
        "  if id <152:\n",
        "    sents = dict()\n",
        "    for j in i:\n",
        "      try:\n",
        "        sents[j] = hate_word_static[j]\n",
        "      except:\n",
        "        sents[j] = 0\n",
        "    \n",
        "    sents = dict(sorted(sents.items(), key=lambda x: x[1], reverse=True))\n",
        "    for j in sents:\n",
        "      try:\n",
        "        wr_w = change_a_word(j)\n",
        "        if wr_w in vocab and len(j) >= 2:\n",
        "          continue\n",
        "        correct_words.append(j)\n",
        "        wrong_words.append(wr_w)\n",
        "        i[i.index(j)] = wr_w\n",
        "        wrong_hate_offensive_cmts.append(' '.join(i))\n",
        "        wrong_type.append(2)\n",
        "        n += 1\n",
        "        break\n",
        "      except:\n",
        "        print(' '.join(i))\n",
        "  else:\n",
        "    sents = dict()\n",
        "    for j in i:\n",
        "      try:\n",
        "        sents[j] = offensive_word_static[j]\n",
        "      except:\n",
        "        sents[j] = 0   \n",
        "\n",
        "    sents = dict(sorted(sents.items(), key=lambda x: x[1], reverse=True))\n",
        "    for j in sents:\n",
        "      try:\n",
        "        wr_w = change_a_word(j)\n",
        "        if wr_w in vocab and len(j) >= 2:\n",
        "          continue       \n",
        "        correct_words.append(j)\n",
        "        wrong_words.append(wr_w)\n",
        "        i[i.index(j)] = wr_w\n",
        "        wrong_hate_offensive_cmts.append(' '.join(i))\n",
        "        wrong_type.append(2)\n",
        "        n += 1\n",
        "        break\n",
        "      except:\n",
        "        print(' '.join(i))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hvpkxg5Uuzyi",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c903b7c1-7ea7-4ed1-f2c4-f59d82520f08"
      },
      "source": [
        "print('correct word length            ', len(correct_words))\n",
        "print('wrong word length              ', len(wrong_words))\n",
        "print('hate and offensive lenght      ', len(hate_offensive_cmts))\n",
        "print('wrong hate and offensive lenght', len(wrong_hate_offensive_cmts))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "correct word length             356\n",
            "wrong word length               356\n",
            "hate and offensive lenght       356\n",
            "wrong hate and offensive lenght 356\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rt720BdJWmZI"
      },
      "source": [
        "Ghi kết quả sau khi tạo lỗi chính tả xuống"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "c5C0NB4V1lyj"
      },
      "source": [
        "# ghi file sai chính tả xuống\n",
        "# importing pandas as pd  \n",
        "import pandas as pd  \n",
        "   \n",
        "# dictionary of lists  \n",
        "temp = {'wrong_type': wrong_type,'correct_words': correct_words, 'wrong_words': wrong_words, 'hate_offensive_cmts': hate_offensive_cmts, 'wrong_hate_offensive_cmts':wrong_hate_offensive_cmts}  \n",
        "     \n",
        "df = pd.DataFrame(temp) \n",
        "  \n",
        "# saving the dataframe \n",
        "df.to_csv('/content/drive/My Drive/Colab Notebooks/KLTN_hatespeech/SuaLoiChinhTa/sai_chinh_ta_khong_dong_nghia.csv') "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EmMSXsGaJlfE"
      },
      "source": [
        "# 2. Sửa lỗi chính tả cho tập dữ liệu hate và offensive"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nS_ppUu7bmbu"
      },
      "source": [
        "## Chỉ xét đúng về mặt hình thức"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mfXKRSB-PfXi"
      },
      "source": [
        "import pandas as pd  \n",
        "data = pd.read_csv('/content/drive/My Drive/Colab Notebooks/KLTN_hatespeech/SuaLoiChinhTa/sai_chinh_ta_khong_dong_nghia.csv')\n",
        "correct_words = data['correct_words']\n",
        "wrong_words   = data['wrong_words']\n",
        "hate_offensive_cmts = data['hate_offensive_cmts']\n",
        "wrong_hate_offensive_cmts = data['wrong_hate_offensive_cmts']\n",
        "\n",
        "correct_words = list(correct_words)\n",
        "for i in range(len(correct_words)):\n",
        "  correct_words[i] = correct_words[i].split('_')\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sn3uvMUDXZVM"
      },
      "source": [
        "# correct_wrong_sents = open('/content/drive/MyDrive/Colab Notebooks/KLTN_hatespeech/SuaLoiChinhTa/gg_output.txt').read().split('\\n')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "l8pyBO47QZlt",
        "outputId": "9da89f43-1ef5-4f19-e550-1a70324c92a8"
      },
      "source": [
        "# thống kê loại lỗi\n",
        "print('Real error                      ', len(data[data['wrong_type'] == 0]))\n",
        "print('Error create by Thin Dataset    ', len(data[data['wrong_type'] == 1]))\n",
        "print('Generate error                  ', len(data[data['wrong_type'] == 2]))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Real error                       1\n",
            "Error create by Thin Dataset     307\n",
            "Generate error                   48\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dE4zFNqXoLkl",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "218613d0-5671-4a0a-f7eb-c5669614c52a"
      },
      "source": [
        "import re \n",
        "!pip install pyvi\n",
        "from pyvi import ViTokenizer\n",
        "def processing_data(sent_list):\n",
        "  sent_list = list(sent_list)\n",
        "  temp = []\n",
        "  for index, i in enumerate(sent_list):\n",
        "    i = re.sub(r\"(.)\\1{2,}\", r\"\\1\\1\", i)\n",
        "    i = re.sub('\\x01', '', i)\n",
        "    i = re.sub('_|\\s+', ' ', i)\n",
        "    i = re.sub(\"\"\"\\!|\\\"|\\#|\\$|\\%|\\&|\\||\\'|\\(|\\)|\\*|\\+|\\,|\\-|\\.|\\/|\\:|\\;|\\<|\\=|\\>|\\?|\\@|\\[|\\\\|\\]|\\^|\\_|\\`|\\{|\\||\\}|\\~\"\"\", '', i)\n",
        "    # i = i.replace('.','')\n",
        "    # i = ViTokenizer.tokenize(i)\n",
        "    sent_list[index] = i\n",
        "  return sent_list"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting pyvi\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/10/e1/0e5bc6b5e3327b9385d6e0f1b0a7c0404f28b74eb6db59a778515b30fd9c/pyvi-0.1-py2.py3-none-any.whl (8.5MB)\n",
            "\u001b[K     |████████████████████████████████| 8.5MB 9.8MB/s \n",
            "\u001b[?25hCollecting sklearn-crfsuite\n",
            "  Downloading https://files.pythonhosted.org/packages/25/74/5b7befa513482e6dee1f3dd68171a6c9dfc14c0eaa00f885ffeba54fe9b0/sklearn_crfsuite-0.3.6-py2.py3-none-any.whl\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.6/dist-packages (from pyvi) (0.22.2.post1)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from sklearn-crfsuite->pyvi) (1.15.0)\n",
            "Requirement already satisfied: tabulate in /usr/local/lib/python3.6/dist-packages (from sklearn-crfsuite->pyvi) (0.8.7)\n",
            "Requirement already satisfied: tqdm>=2.0 in /usr/local/lib/python3.6/dist-packages (from sklearn-crfsuite->pyvi) (4.41.1)\n",
            "Collecting python-crfsuite>=0.8.3\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/95/99/869dde6dbf3e0d07a013c8eebfb0a3d30776334e0097f8432b631a9a3a19/python_crfsuite-0.9.7-cp36-cp36m-manylinux1_x86_64.whl (743kB)\n",
            "\u001b[K     |████████████████████████████████| 747kB 43.4MB/s \n",
            "\u001b[?25hRequirement already satisfied: scipy>=0.17.0 in /usr/local/lib/python3.6/dist-packages (from scikit-learn->pyvi) (1.4.1)\n",
            "Requirement already satisfied: numpy>=1.11.0 in /usr/local/lib/python3.6/dist-packages (from scikit-learn->pyvi) (1.19.5)\n",
            "Requirement already satisfied: joblib>=0.11 in /usr/local/lib/python3.6/dist-packages (from scikit-learn->pyvi) (1.0.0)\n",
            "Installing collected packages: python-crfsuite, sklearn-crfsuite, pyvi\n",
            "Successfully installed python-crfsuite-0.9.7 pyvi-0.1 sklearn-crfsuite-0.3.6\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Uivt-Gu1h0sR"
      },
      "source": [
        "import sys\n",
        "sys.path.append('/content/drive/My Drive/Colab Notebooks/MaliciousSpellingCorrection - Copy')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OGVBccFfZl-J"
      },
      "source": [
        "Thử nghiệm với mô hình SKIP-GRAM, CBOW, FASTTEXT"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ubC3WxXtjyJe",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "370a1b04-bdd2-4b1f-b33d-9bbee48d18c3"
      },
      "source": [
        "!pip install pyxDamerauLevenshtein\n",
        "!pip install unidecode"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting pyxDamerauLevenshtein\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/6d/3f/5f9448c147bc5c3d789ef0a02177ae86c4cbd1d395fe11f81361df0d5003/pyxDamerauLevenshtein-1.6.1.tar.gz (55kB)\n",
            "\r\u001b[K     |██████                          | 10kB 19.1MB/s eta 0:00:01\r\u001b[K     |███████████▉                    | 20kB 24.7MB/s eta 0:00:01\r\u001b[K     |█████████████████▉              | 30kB 16.8MB/s eta 0:00:01\r\u001b[K     |███████████████████████▊        | 40kB 11.6MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████▊  | 51kB 13.1MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 61kB 3.7MB/s \n",
            "\u001b[?25h  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "    Preparing wheel metadata ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: numpy>=1.16.1 in /usr/local/lib/python3.6/dist-packages (from pyxDamerauLevenshtein) (1.19.5)\n",
            "Building wheels for collected packages: pyxDamerauLevenshtein\n",
            "  Building wheel for pyxDamerauLevenshtein (PEP 517) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for pyxDamerauLevenshtein: filename=pyxDamerauLevenshtein-1.6.1-cp36-cp36m-linux_x86_64.whl size=85760 sha256=58b147bfcdc4b28dddff5f4a538fb930af29d27e68e0237170335ecad0ce7682\n",
            "  Stored in directory: /root/.cache/pip/wheels/d2/05/c3/989929774aa6f86a368f18f132bcc79ed7cb1ea65763c1dc09\n",
            "Successfully built pyxDamerauLevenshtein\n",
            "Installing collected packages: pyxDamerauLevenshtein\n",
            "Successfully installed pyxDamerauLevenshtein-1.6.1\n",
            "Collecting unidecode\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/74/65/91eab655041e9e92f948cb7302e54962035762ce7b518272ed9d6b269e93/Unidecode-1.1.2-py2.py3-none-any.whl (239kB)\n",
            "\u001b[K     |████████████████████████████████| 245kB 9.3MB/s \n",
            "\u001b[?25hInstalling collected packages: unidecode\n",
            "Successfully installed unidecode-1.1.2\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zxb93B0AXZrv",
        "outputId": "281f6fbd-691d-471c-a19c-a97f19696b4e"
      },
      "source": [
        "method = ['skip-gram', 'cbow', 'fasttext_fb', 'fasttext_vne']\r\n",
        "for m in method:\r\n",
        "  from spelling_checking import spelling_checking\r\n",
        "  small_corpus_dir = '/content/drive/My Drive/Colab Notebooks/KLTN_hatespeech/small_corpus1.txt'\r\n",
        "  badwords_dir = '/content/drive/My Drive/Colab Notebooks/KLTN_hatespeech/hate_offensive_vocab.txt'\r\n",
        "  spelling_checking = spelling_checking(\"/content/drive/My Drive/Colab Notebooks/KLTN_hatespeech/Model/\"+m+\"/\", \"vocab.txt\", \"vec.npy\", small_corpus_dir, badwords_dir, CAND_LIMIT=8 )\r\n",
        "  spelling_checking.readData()\r\n",
        "  wrong_sents = processing_data(wrong_hate_offensive_cmts)\r\n",
        "  # sửa cho tập train và lưu xuống\r\n",
        "  correct_wrong_sents,_,_ = spelling_checking.generateAlgoCandCorrection(wrong_sents,3)\r\n",
        "\r\n",
        "  temp = []\r\n",
        "  for i in correct_wrong_sents:\r\n",
        "    temp.append(' '.join(i))\r\n",
        "  correct_wrong_sents = temp\r\n",
        "\r\n",
        "  dung = 0\r\n",
        "  sai = 0\r\n",
        "  sot = 0\r\n",
        "  s = ''\r\n",
        "  for index, i in enumerate(correct_wrong_sents):\r\n",
        "    i = i.split()\r\n",
        "    # if correct_words[index] in i:\r\n",
        "    if set(correct_words[index]) & set(i) != set():\r\n",
        "      dung +=1\r\n",
        "      s = (s  + 'ĐÚNG\\n'\r\n",
        "              + 'Từ sai:  ' + wrong_words[index] + '\\t Từ gốc: ' +  '_'.join(correct_words[index]) + '\\n'\r\n",
        "              + 'Câu sửa: ' + correct_wrong_sents[index] + '\\n'\r\n",
        "              + 'Câu gốc: ' + hate_offensive_cmts[index] + '\\n'\r\n",
        "              + 'Câu sai: ' + wrong_hate_offensive_cmts[index] + '\\n'\r\n",
        "              + '----------------------------\\n\\n')\r\n",
        "    else:\r\n",
        "      sai += 1\r\n",
        "      s = s + 'SAI'\r\n",
        "      if wrong_words[index] in i:\r\n",
        "        sot += 1 \r\n",
        "        s = s + ' SÓT'\r\n",
        "      s = (s  + '\\n'\r\n",
        "              + 'Từ sai:  ' + wrong_words[index] + '\\t Từ gốc: ' +  '_'.join(correct_words[index]) + '\\n'\r\n",
        "              + 'Câu sửa: ' + correct_wrong_sents[index] + '\\n'\r\n",
        "              + 'Câu gốc: ' + hate_offensive_cmts[index] + '\\n'\r\n",
        "              + 'Câu sai: ' + wrong_hate_offensive_cmts[index] + '\\n'\r\n",
        "              + '----------------------------\\n\\n')\r\n",
        "  # ghi file dữ liệu xuống\r\n",
        "  open('/content/drive/MyDrive/Colab Notebooks/KLTN_hatespeech/log_result/hate_offensive/' + m + '_kdn.txt', 'w').write(s)\r\n",
        "\r\n",
        "  print(\"\\n\\n=================================\")\r\n",
        "  print(\"METHOD:  \", m.upper())\r\n",
        "  print('SL đúng:', dung)\r\n",
        "  print('SL sai :', sai)\r\n",
        "  print('SL sót :', sot)\r\n",
        "  print('Acc    :', dung*100/(dung+sai), '%')\r\n",
        "  print('TL sót :', sot*100/(dung+sai), '%')\r\n",
        "  print('TL phát hiện     :', 100 - sot*100/(dung+sai), '%')\r\n",
        "  print('TL đúng/phát hiện:', dung*100/(dung+sai-sot), '%')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Done loading vocabulary.\n",
            "Done loading vectors.\n",
            "Corpus length          13509\n",
            "Small corpus length    2069\n",
            "Badwords length        1002\n",
            "stage 1\n",
            "done stage 1: raw check on edit distance\n",
            "stage 2.\n",
            "done stage 2: context-dependent check.\n",
            "\n",
            "\n",
            "=================================\n",
            "METHOD:   SKIP-GRAM\n",
            "SL đúng: 267\n",
            "SL sai : 89\n",
            "SL sót : 9\n",
            "Acc    : 75.0 %\n",
            "TL sót : 2.5280898876404496 %\n",
            "TL phát hiện     : 97.47191011235955 %\n",
            "TL đúng/phát hiện: 76.94524495677233 %\n",
            "Done loading vocabulary.\n",
            "Done loading vectors.\n",
            "Corpus length          13509\n",
            "Small corpus length    2069\n",
            "Badwords length        1002\n",
            "stage 1\n",
            "done stage 1: raw check on edit distance\n",
            "stage 2.\n",
            "done stage 2: context-dependent check.\n",
            "\n",
            "\n",
            "=================================\n",
            "METHOD:   CBOW\n",
            "SL đúng: 260\n",
            "SL sai : 96\n",
            "SL sót : 13\n",
            "Acc    : 73.03370786516854 %\n",
            "TL sót : 3.651685393258427 %\n",
            "TL phát hiện     : 96.34831460674157 %\n",
            "TL đúng/phát hiện: 75.80174927113703 %\n",
            "Done loading vocabulary.\n",
            "Done loading vectors.\n",
            "Corpus length          13023\n",
            "Small corpus length    2069\n",
            "Badwords length        1002\n",
            "stage 1\n",
            "done stage 1: raw check on edit distance\n",
            "stage 2.\n",
            "done stage 2: context-dependent check.\n",
            "\n",
            "\n",
            "=================================\n",
            "METHOD:   FASTTEXT_FB\n",
            "SL đúng: 243\n",
            "SL sai : 113\n",
            "SL sót : 14\n",
            "Acc    : 68.25842696629213 %\n",
            "TL sót : 3.932584269662921 %\n",
            "TL phát hiện     : 96.06741573033707 %\n",
            "TL đúng/phát hiện: 71.05263157894737 %\n",
            "Done loading vocabulary.\n",
            "Done loading vectors.\n",
            "Corpus length          13509\n",
            "Small corpus length    2069\n",
            "Badwords length        1002\n",
            "stage 1\n",
            "done stage 1: raw check on edit distance\n",
            "stage 2.\n",
            "done stage 2: context-dependent check.\n",
            "\n",
            "\n",
            "=================================\n",
            "METHOD:   FASTTEXT_VNE\n",
            "SL đúng: 253\n",
            "SL sai : 103\n",
            "SL sót : 16\n",
            "Acc    : 71.06741573033707 %\n",
            "TL sót : 4.49438202247191 %\n",
            "TL phát hiện     : 95.50561797752809 %\n",
            "TL đúng/phát hiện: 74.41176470588235 %\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TdbjeTNJZz5-"
      },
      "source": [
        "Thử nghiệm với mô hình symspell"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BqRtNFinZ_qs"
      },
      "source": [
        "!pip install -U symspellpy\r\n",
        "import pkg_resources\r\n",
        "from symspellpy import SymSpell, Verbosity\r\n",
        "# Khởi tạo\r\n",
        "sym_spell = SymSpell(max_dictionary_edit_distance=2, prefix_length=7)\r\n",
        "sym_spell.load_dictionary('/content/drive/MyDrive/Colab Notebooks/KLTN_hatespeech/SymSpell/monogram.txt', term_index=0, count_index=1)\r\n",
        "sym_spell.load_bigram_dictionary('/content/drive/MyDrive/Colab Notebooks/KLTN_hatespeech/SymSpell/bigram.txt', term_index=0, count_index=2)\r\n",
        "# sửa lỗi\r\n",
        "correct_wrong_sents = []\r\n",
        "for i in wrong_hate_offensive_cmts:\r\n",
        "  # max edit distance per lookup (per single word, not per whole input string)\r\n",
        "  suggestions = sym_spell.lookup_compound(i, max_edit_distance=2)\r\n",
        "  correct_wrong_sents.append(suggestions[0].term)\r\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1aVEMBJ5aOYC",
        "outputId": "aa926b39-9f08-4c82-83af-928e3d4d9364"
      },
      "source": [
        "dung = 0\r\n",
        "sai = 0\r\n",
        "sot = 0\r\n",
        "s = ''\r\n",
        "# Đánh giá\r\n",
        "for index, i in enumerate(correct_wrong_sents):\r\n",
        "  i = i.split()\r\n",
        "  # if correct_words[index] in i:\r\n",
        "  if set(correct_words[index]) & set(i) != set():\r\n",
        "    dung +=1\r\n",
        "    s = (s  + 'ĐÚNG\\n'\r\n",
        "            + 'Từ sai:  ' + wrong_words[index] + '\\t Từ gốc: ' +  '_'.join(correct_words[index]) + '\\n'\r\n",
        "            + 'Câu sửa: ' + correct_wrong_sents[index] + '\\n'\r\n",
        "            + 'Câu gốc: ' + hate_offensive_cmts[index] + '\\n'\r\n",
        "            + 'Câu sai: ' + wrong_hate_offensive_cmts[index] + '\\n'\r\n",
        "            + '----------------------------\\n\\n')\r\n",
        "  else:\r\n",
        "    sai += 1\r\n",
        "    s = s + 'SAI'\r\n",
        "    if wrong_words[index] in i:\r\n",
        "      sot += 1 \r\n",
        "      s = s + ' SÓT'\r\n",
        "    s = (s  + '\\n'\r\n",
        "            + 'Từ sai:  ' + wrong_words[index] + '\\t Từ gốc: ' +  '_'.join(correct_words[index]) + '\\n'\r\n",
        "            + 'Câu sửa: ' + correct_wrong_sents[index] + '\\n'\r\n",
        "            + 'Câu gốc: ' + hate_offensive_cmts[index] + '\\n'\r\n",
        "            + 'Câu sai: ' + wrong_hate_offensive_cmts[index] + '\\n'\r\n",
        "            + '----------------------------\\n\\n')\r\n",
        "# ghi file dữ liệu xuống\r\n",
        "open('/content/drive/MyDrive/Colab Notebooks/KLTN_hatespeech/log_result/hate_offensive/symspell_kdn.txt', 'w').write(s)\r\n",
        "\r\n",
        "print(\"\\n\\n=================================\")\r\n",
        "print(\"METHOD:  \", 'SYMSPELL')\r\n",
        "print('SL đúng:', dung)\r\n",
        "print('SL sai :', sai)\r\n",
        "print('SL sót :', sot)\r\n",
        "print('Acc    :', dung*100/(dung+sai), '%')\r\n",
        "print('TL sót :', sot*100/(dung+sai), '%')\r\n",
        "print('TL phát hiện     :', 100 - sot*100/(dung+sai), '%')\r\n",
        "print('TL đúng/phát hiện:', dung*100/(dung+sai-sot), '%')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\n",
            "\n",
            "=================================\n",
            "METHOD:   SYMSPELL\n",
            "SL đúng: 253\n",
            "SL sai : 103\n",
            "SL sót : 16\n",
            "Acc    : 71.06741573033707 %\n",
            "TL sót : 4.49438202247191 %\n",
            "TL phát hiện     : 95.50561797752809 %\n",
            "TL đúng/phát hiện: 74.41176470588235 %\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aoVUD_THarKw"
      },
      "source": [
        "Thử nghiệm với GOOGLE SPELL CHECKER"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tFBfF04KawwI"
      },
      "source": [
        "# load file google đã sửa lên\r\n",
        "correct_wrong_sents = open('/content/drive/MyDrive/Colab Notebooks/KLTN_hatespeech/SuaLoiChinhTa/gg_output.txt').read().split('\\n')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zjjAq7LgbE52",
        "outputId": "1295fc11-41b7-45d9-95aa-2cf0f6213b36"
      },
      "source": [
        "dung = 0\r\n",
        "sai = 0\r\n",
        "sot = 0\r\n",
        "s = ''\r\n",
        "# Đánh giá\r\n",
        "for index, i in enumerate(correct_wrong_sents):\r\n",
        "  i = i.split()\r\n",
        "  # if correct_words[index] in i:\r\n",
        "  if set(correct_words[index]) & set(i) != set():\r\n",
        "    dung +=1\r\n",
        "    s = (s  + 'ĐÚNG\\n'\r\n",
        "            + 'Từ sai:  ' + wrong_words[index] + '\\t Từ gốc: ' +  '_'.join(correct_words[index]) + '\\n'\r\n",
        "            + 'Câu sửa: ' + correct_wrong_sents[index] + '\\n'\r\n",
        "            + 'Câu gốc: ' + hate_offensive_cmts[index] + '\\n'\r\n",
        "            + 'Câu sai: ' + wrong_hate_offensive_cmts[index] + '\\n'\r\n",
        "            + '----------------------------\\n\\n')\r\n",
        "  else:\r\n",
        "    sai += 1\r\n",
        "    s = s + 'SAI'\r\n",
        "    if wrong_words[index] in i:\r\n",
        "      sot += 1 \r\n",
        "      s = s + ' SÓT'\r\n",
        "    s = (s  + '\\n'\r\n",
        "            + 'Từ sai:  ' + wrong_words[index] + '\\t Từ gốc: ' +  '_'.join(correct_words[index]) + '\\n'\r\n",
        "            + 'Câu sửa: ' + correct_wrong_sents[index] + '\\n'\r\n",
        "            + 'Câu gốc: ' + hate_offensive_cmts[index] + '\\n'\r\n",
        "            + 'Câu sai: ' + wrong_hate_offensive_cmts[index] + '\\n'\r\n",
        "            + '----------------------------\\n\\n')\r\n",
        "# ghi file dữ liệu xuống\r\n",
        "open('/content/drive/MyDrive/Colab Notebooks/KLTN_hatespeech/log_result/hate_offensive/google_kdn.txt', 'w').write(s)\r\n",
        "\r\n",
        "print(\"\\n\\n=================================\")\r\n",
        "print(\"METHOD:  \", 'GOOGLE')\r\n",
        "print('SL đúng:', dung)\r\n",
        "print('SL sai :', sai)\r\n",
        "print('SL sót :', sot)\r\n",
        "print('Acc    :', dung*100/(dung+sai), '%')\r\n",
        "print('TL sót :', sot*100/(dung+sai), '%')\r\n",
        "print('TL phát hiện     :', 100 - sot*100/(dung+sai), '%')\r\n",
        "print('TL đúng/phát hiện:', dung*100/(dung+sai-sot), '%')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\n",
            "\n",
            "=================================\n",
            "METHOD:   GOOGLE\n",
            "SL đúng: 143\n",
            "SL sai : 213\n",
            "SL sót : 168\n",
            "Acc    : 40.168539325842694 %\n",
            "TL sót : 47.19101123595506 %\n",
            "TL phát hiện     : 52.80898876404494 %\n",
            "TL đúng/phát hiện: 76.06382978723404 %\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oaOJD5dOb1ED"
      },
      "source": [
        "## Xét về mặt ngữ nghĩa"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wVAyoSIob1EN"
      },
      "source": [
        "import pandas as pd  \n",
        "data = pd.read_csv('/content/drive/My Drive/Colab Notebooks/KLTN_hatespeech/SuaLoiChinhTa/sai_chinh_ta_dong_nghia.csv')\n",
        "correct_words = data['correct_words']\n",
        "wrong_words   = data['wrong_words']\n",
        "hate_offensive_cmts = data['hate_offensive_cmts']\n",
        "wrong_hate_offensive_cmts = data['wrong_hate_offensive_cmts']\n",
        "\n",
        "correct_words = list(correct_words)\n",
        "for i in range(len(correct_words)):\n",
        "  correct_words[i] = correct_words[i].split('_')\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cePTeMp-b1EN",
        "outputId": "8748d8f7-1b22-46f2-883c-434c6673ad0b"
      },
      "source": [
        "# thống kê loại lỗi\n",
        "print('Real error                      ', len(data[data['wrong_type'] == 0]))\n",
        "print('Error create by Thin Dataset    ', len(data[data['wrong_type'] == 1]))\n",
        "print('Generate error                  ', len(data[data['wrong_type'] == 2]))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Real error                       1\n",
            "Error create by Thin Dataset     307\n",
            "Generate error                   48\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0gI3JgVhb1EP",
        "outputId": "60903ba6-c9f8-435f-df71-59a8a39e6c77"
      },
      "source": [
        "import re \n",
        "!pip install pyvi\n",
        "from pyvi import ViTokenizer\n",
        "def processing_data(sent_list):\n",
        "  sent_list = list(sent_list)\n",
        "  temp = []\n",
        "  for index, i in enumerate(sent_list):\n",
        "    i = re.sub(r\"(.)\\1{2,}\", r\"\\1\\1\", i)\n",
        "    i = re.sub('\\x01', '', i)\n",
        "    i = re.sub('_|\\s+', ' ', i)\n",
        "    i = re.sub(\"\"\"\\!|\\\"|\\#|\\$|\\%|\\&|\\||\\'|\\(|\\)|\\*|\\+|\\,|\\-|\\.|\\/|\\:|\\;|\\<|\\=|\\>|\\?|\\@|\\[|\\\\|\\]|\\^|\\_|\\`|\\{|\\||\\}|\\~\"\"\", '', i)\n",
        "    # i = i.replace('.','')\n",
        "    # i = ViTokenizer.tokenize(i)\n",
        "    sent_list[index] = i\n",
        "  return sent_list"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: pyvi in /usr/local/lib/python3.6/dist-packages (0.1)\n",
            "Requirement already satisfied: sklearn-crfsuite in /usr/local/lib/python3.6/dist-packages (from pyvi) (0.3.6)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.6/dist-packages (from pyvi) (0.22.2.post1)\n",
            "Requirement already satisfied: python-crfsuite>=0.8.3 in /usr/local/lib/python3.6/dist-packages (from sklearn-crfsuite->pyvi) (0.9.7)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from sklearn-crfsuite->pyvi) (1.15.0)\n",
            "Requirement already satisfied: tqdm>=2.0 in /usr/local/lib/python3.6/dist-packages (from sklearn-crfsuite->pyvi) (4.41.1)\n",
            "Requirement already satisfied: tabulate in /usr/local/lib/python3.6/dist-packages (from sklearn-crfsuite->pyvi) (0.8.7)\n",
            "Requirement already satisfied: scipy>=0.17.0 in /usr/local/lib/python3.6/dist-packages (from scikit-learn->pyvi) (1.4.1)\n",
            "Requirement already satisfied: joblib>=0.11 in /usr/local/lib/python3.6/dist-packages (from scikit-learn->pyvi) (1.0.0)\n",
            "Requirement already satisfied: numpy>=1.11.0 in /usr/local/lib/python3.6/dist-packages (from scikit-learn->pyvi) (1.19.5)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3L6dqCdpb1EP"
      },
      "source": [
        "import sys\n",
        "sys.path.append('/content/drive/My Drive/Colab Notebooks/MaliciousSpellingCorrection - Copy')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "O4RMrnP8b1EP"
      },
      "source": [
        "Thử nghiệm với mô hình SKIP-GRAM, CBOW, FASTTEXT"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5xkIjyfab1EQ",
        "outputId": "0f68d88e-37ef-4b99-a7ad-b50679ba83d3"
      },
      "source": [
        "!pip install pyxDamerauLevenshtein\n",
        "!pip install unidecode"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: pyxDamerauLevenshtein in /usr/local/lib/python3.6/dist-packages (1.6.1)\n",
            "Requirement already satisfied: numpy>=1.16.1 in /usr/local/lib/python3.6/dist-packages (from pyxDamerauLevenshtein) (1.19.5)\n",
            "Requirement already satisfied: unidecode in /usr/local/lib/python3.6/dist-packages (1.1.2)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4BB-4iEMb1EQ",
        "outputId": "be926721-e589-4de1-afb8-415b3cc2e9f3"
      },
      "source": [
        "method = ['skip-gram', 'cbow', 'fasttext_fb', 'fasttext_vne']\r\n",
        "for m in method:\r\n",
        "  from spelling_checking import spelling_checking\r\n",
        "  small_corpus_dir = '/content/drive/My Drive/Colab Notebooks/KLTN_hatespeech/small_corpus1.txt'\r\n",
        "  badwords_dir = '/content/drive/My Drive/Colab Notebooks/KLTN_hatespeech/hate_offensive_vocab.txt'\r\n",
        "  spelling_checking = spelling_checking(\"/content/drive/My Drive/Colab Notebooks/KLTN_hatespeech/Model/\"+m+\"/\", \"vocab.txt\", \"vec.npy\", small_corpus_dir, badwords_dir, CAND_LIMIT=8 )\r\n",
        "  spelling_checking.readData()\r\n",
        "  wrong_sents = processing_data(wrong_hate_offensive_cmts)\r\n",
        "  # sửa cho tập train và lưu xuống\r\n",
        "  correct_wrong_sents,_,_ = spelling_checking.generateAlgoCandCorrection(wrong_sents,3)\r\n",
        "\r\n",
        "  temp = []\r\n",
        "  for i in correct_wrong_sents:\r\n",
        "    temp.append(' '.join(i))\r\n",
        "  correct_wrong_sents = temp\r\n",
        "\r\n",
        "  dung = 0\r\n",
        "  sai = 0\r\n",
        "  sot = 0\r\n",
        "  s = ''\r\n",
        "  for index, i in enumerate(correct_wrong_sents):\r\n",
        "    i = i.split()\r\n",
        "    # if correct_words[index] in i:\r\n",
        "    if set(correct_words[index]) & set(i) != set():\r\n",
        "      dung +=1\r\n",
        "      s = (s  + 'ĐÚNG\\n'\r\n",
        "              + 'Từ sai:  ' + wrong_words[index] + '\\t Từ gốc: ' +  '_'.join(correct_words[index]) + '\\n'\r\n",
        "              + 'Câu sửa: ' + correct_wrong_sents[index] + '\\n'\r\n",
        "              + 'Câu gốc: ' + hate_offensive_cmts[index] + '\\n'\r\n",
        "              + 'Câu sai: ' + wrong_hate_offensive_cmts[index] + '\\n'\r\n",
        "              + '----------------------------\\n\\n')\r\n",
        "    else:\r\n",
        "      sai += 1\r\n",
        "      s = s + 'SAI'\r\n",
        "      if wrong_words[index] in i:\r\n",
        "        sot += 1 \r\n",
        "        s = s + ' SÓT'\r\n",
        "      s = (s  + '\\n'\r\n",
        "              + 'Từ sai:  ' + wrong_words[index] + '\\t Từ gốc: ' +  '_'.join(correct_words[index]) + '\\n'\r\n",
        "              + 'Câu sửa: ' + correct_wrong_sents[index] + '\\n'\r\n",
        "              + 'Câu gốc: ' + hate_offensive_cmts[index] + '\\n'\r\n",
        "              + 'Câu sai: ' + wrong_hate_offensive_cmts[index] + '\\n'\r\n",
        "              + '----------------------------\\n\\n')\r\n",
        "  # ghi file dữ liệu xuống\r\n",
        "  open('/content/drive/MyDrive/Colab Notebooks/KLTN_hatespeech/log_result/hate_offensive/' + m + '_dn.txt', 'w').write(s)\r\n",
        "\r\n",
        "  print(\"\\n\\n=================================\")\r\n",
        "  print(\"METHOD:  \", m.upper())\r\n",
        "  print('SL đúng:', dung)\r\n",
        "  print('SL sai :', sai)\r\n",
        "  print('SL sót :', sot)\r\n",
        "  print('Acc    :', dung*100/(dung+sai), '%')\r\n",
        "  print('TL sót :', sot*100/(dung+sai), '%')\r\n",
        "  print('TL phát hiện     :', 100 - sot*100/(dung+sai), '%')\r\n",
        "  print('TL đúng/phát hiện:', dung*100/(dung+sai-sot), '%')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Done loading vocabulary.\n",
            "Done loading vectors.\n",
            "Corpus length          13509\n",
            "Small corpus length    2069\n",
            "Badwords length        1002\n",
            "stage 1\n",
            "done stage 1: raw check on edit distance\n",
            "stage 2.\n",
            "done stage 2: context-dependent check.\n",
            "\n",
            "\n",
            "=================================\n",
            "METHOD:   SKIP-GRAM\n",
            "SL đúng: 291\n",
            "SL sai : 65\n",
            "SL sót : 9\n",
            "Acc    : 81.74157303370787 %\n",
            "TL sót : 2.5280898876404496 %\n",
            "TL phát hiện     : 97.47191011235955 %\n",
            "TL đúng/phát hiện: 83.86167146974063 %\n",
            "Done loading vocabulary.\n",
            "Done loading vectors.\n",
            "Corpus length          13509\n",
            "Small corpus length    2069\n",
            "Badwords length        1002\n",
            "stage 1\n",
            "done stage 1: raw check on edit distance\n",
            "stage 2.\n",
            "done stage 2: context-dependent check.\n",
            "\n",
            "\n",
            "=================================\n",
            "METHOD:   CBOW\n",
            "SL đúng: 276\n",
            "SL sai : 80\n",
            "SL sót : 13\n",
            "Acc    : 77.52808988764045 %\n",
            "TL sót : 3.651685393258427 %\n",
            "TL phát hiện     : 96.34831460674157 %\n",
            "TL đúng/phát hiện: 80.466472303207 %\n",
            "Done loading vocabulary.\n",
            "Done loading vectors.\n",
            "Corpus length          13023\n",
            "Small corpus length    2069\n",
            "Badwords length        1002\n",
            "stage 1\n",
            "done stage 1: raw check on edit distance\n",
            "stage 2.\n",
            "done stage 2: context-dependent check.\n",
            "\n",
            "\n",
            "=================================\n",
            "METHOD:   FASTTEXT_FB\n",
            "SL đúng: 275\n",
            "SL sai : 81\n",
            "SL sót : 13\n",
            "Acc    : 77.24719101123596 %\n",
            "TL sót : 3.651685393258427 %\n",
            "TL phát hiện     : 96.34831460674157 %\n",
            "TL đúng/phát hiện: 80.17492711370262 %\n",
            "Done loading vocabulary.\n",
            "Done loading vectors.\n",
            "Corpus length          13509\n",
            "Small corpus length    2069\n",
            "Badwords length        1002\n",
            "stage 1\n",
            "done stage 1: raw check on edit distance\n",
            "stage 2.\n",
            "done stage 2: context-dependent check.\n",
            "\n",
            "\n",
            "=================================\n",
            "METHOD:   FASTTEXT_VNE\n",
            "SL đúng: 272\n",
            "SL sai : 84\n",
            "SL sót : 16\n",
            "Acc    : 76.40449438202248 %\n",
            "TL sót : 4.49438202247191 %\n",
            "TL phát hiện     : 95.50561797752809 %\n",
            "TL đúng/phát hiện: 80.0 %\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "K1pc21YLb1ER"
      },
      "source": [
        "Thử nghiệm với mô hình symspell"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "q2wKz3zrb1ER",
        "outputId": "e70cc825-5e08-404c-d6c5-ded2bab233e5"
      },
      "source": [
        "!pip install -U symspellpy\r\n",
        "import pkg_resources\r\n",
        "from symspellpy import SymSpell, Verbosity\r\n",
        "# Khởi tạo\r\n",
        "sym_spell = SymSpell(max_dictionary_edit_distance=2, prefix_length=7)\r\n",
        "sym_spell.load_dictionary('/content/drive/MyDrive/Colab Notebooks/KLTN_hatespeech/SymSpell/monogram.txt', term_index=0, count_index=1)\r\n",
        "sym_spell.load_bigram_dictionary('/content/drive/MyDrive/Colab Notebooks/KLTN_hatespeech/SymSpell/bigram.txt', term_index=0, count_index=2)\r\n",
        "# sửa lỗi\r\n",
        "correct_wrong_sents = []\r\n",
        "for i in wrong_hate_offensive_cmts:\r\n",
        "  # max edit distance per lookup (per single word, not per whole input string)\r\n",
        "  suggestions = sym_spell.lookup_compound(i, max_edit_distance=2)\r\n",
        "  correct_wrong_sents.append(suggestions[0].term)\r\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting symspellpy\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/99/af/e71fcca6a42b6a63f518b0c1627e1f67822815cb0cf71e6af05acbd75c78/symspellpy-6.7.0-py3-none-any.whl (2.6MB)\n",
            "\u001b[K     |████████████████████████████████| 2.6MB 11.7MB/s \n",
            "\u001b[?25hRequirement already satisfied, skipping upgrade: numpy>=1.13.1 in /usr/local/lib/python3.6/dist-packages (from symspellpy) (1.19.5)\n",
            "Installing collected packages: symspellpy\n",
            "Successfully installed symspellpy-6.7.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KJaP9BLob1ER",
        "outputId": "f8d086ee-89d9-4cdd-b165-1732a0e62a33"
      },
      "source": [
        "dung = 0\r\n",
        "sai = 0\r\n",
        "sot = 0\r\n",
        "s = ''\r\n",
        "# Đánh giá\r\n",
        "for index, i in enumerate(correct_wrong_sents):\r\n",
        "  i = i.split()\r\n",
        "  # if correct_words[index] in i:\r\n",
        "  if set(correct_words[index]) & set(i) != set():\r\n",
        "    dung +=1\r\n",
        "    s = (s  + 'ĐÚNG\\n'\r\n",
        "            + 'Từ sai:  ' + wrong_words[index] + '\\t Từ gốc: ' +  '_'.join(correct_words[index]) + '\\n'\r\n",
        "            + 'Câu sửa: ' + correct_wrong_sents[index] + '\\n'\r\n",
        "            + 'Câu gốc: ' + hate_offensive_cmts[index] + '\\n'\r\n",
        "            + 'Câu sai: ' + wrong_hate_offensive_cmts[index] + '\\n'\r\n",
        "            + '----------------------------\\n\\n')\r\n",
        "  else:\r\n",
        "    sai += 1\r\n",
        "    s = s + 'SAI'\r\n",
        "    if wrong_words[index] in i:\r\n",
        "      sot += 1 \r\n",
        "      s = s + ' SÓT'\r\n",
        "    s = (s  + '\\n'\r\n",
        "            + 'Từ sai:  ' + wrong_words[index] + '\\t Từ gốc: ' +  '_'.join(correct_words[index]) + '\\n'\r\n",
        "            + 'Câu sửa: ' + correct_wrong_sents[index] + '\\n'\r\n",
        "            + 'Câu gốc: ' + hate_offensive_cmts[index] + '\\n'\r\n",
        "            + 'Câu sai: ' + wrong_hate_offensive_cmts[index] + '\\n'\r\n",
        "            + '----------------------------\\n\\n')\r\n",
        "# ghi file dữ liệu xuống\r\n",
        "open('/content/drive/MyDrive/Colab Notebooks/KLTN_hatespeech/log_result/hate_offensive/symspell_dn.txt', 'w').write(s)\r\n",
        "\r\n",
        "print(\"\\n\\n=================================\")\r\n",
        "print(\"METHOD:  \", 'SYMSPELL')\r\n",
        "print('SL đúng:', dung)\r\n",
        "print('SL sai :', sai)\r\n",
        "print('SL sót :', sot)\r\n",
        "print('Acc    :', dung*100/(dung+sai), '%')\r\n",
        "print('TL sót :', sot*100/(dung+sai), '%')\r\n",
        "print('TL phát hiện     :', 100 - sot*100/(dung+sai), '%')\r\n",
        "print('TL đúng/phát hiện:', dung*100/(dung+sai-sot), '%')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\n",
            "\n",
            "=================================\n",
            "METHOD:   SYMSPELL\n",
            "SL đúng: 269\n",
            "SL sai : 87\n",
            "SL sót : 7\n",
            "Acc    : 75.56179775280899 %\n",
            "TL sót : 1.9662921348314606 %\n",
            "TL phát hiện     : 98.03370786516854 %\n",
            "TL đúng/phát hiện: 77.07736389684814 %\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nk12L0Ezb1ES"
      },
      "source": [
        "Thử nghiệm với GOOGLE SPELL CHECKER"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GdO7QBVzb1ES"
      },
      "source": [
        "# load file google đã sửa lên\r\n",
        "correct_wrong_sents = open('/content/drive/MyDrive/Colab Notebooks/KLTN_hatespeech/SuaLoiChinhTa/gg_output.txt').read().split('\\n')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tpxdeY29b1ES",
        "outputId": "8105e9db-ee82-45f6-fb42-5a952bc06e1d"
      },
      "source": [
        "dung = 0\r\n",
        "sai = 0\r\n",
        "sot = 0\r\n",
        "s = ''\r\n",
        "# Đánh giá\r\n",
        "for index, i in enumerate(correct_wrong_sents):\r\n",
        "  i = i.split()\r\n",
        "  # if correct_words[index] in i:\r\n",
        "  if set(correct_words[index]) & set(i) != set():\r\n",
        "    dung +=1\r\n",
        "    s = (s  + 'ĐÚNG\\n'\r\n",
        "            + 'Từ sai:  ' + wrong_words[index] + '\\t Từ gốc: ' +  '_'.join(correct_words[index]) + '\\n'\r\n",
        "            + 'Câu sửa: ' + correct_wrong_sents[index] + '\\n'\r\n",
        "            + 'Câu gốc: ' + hate_offensive_cmts[index] + '\\n'\r\n",
        "            + 'Câu sai: ' + wrong_hate_offensive_cmts[index] + '\\n'\r\n",
        "            + '----------------------------\\n\\n')\r\n",
        "  else:\r\n",
        "    sai += 1\r\n",
        "    s = s + 'SAI'\r\n",
        "    if wrong_words[index] in i:\r\n",
        "      sot += 1 \r\n",
        "      s = s + ' SÓT'\r\n",
        "    s = (s  + '\\n'\r\n",
        "            + 'Từ sai:  ' + wrong_words[index] + '\\t Từ gốc: ' +  '_'.join(correct_words[index]) + '\\n'\r\n",
        "            + 'Câu sửa: ' + correct_wrong_sents[index] + '\\n'\r\n",
        "            + 'Câu gốc: ' + hate_offensive_cmts[index] + '\\n'\r\n",
        "            + 'Câu sai: ' + wrong_hate_offensive_cmts[index] + '\\n'\r\n",
        "            + '----------------------------\\n\\n')\r\n",
        "# ghi file dữ liệu xuống\r\n",
        "open('/content/drive/MyDrive/Colab Notebooks/KLTN_hatespeech/log_result/hate_offensive/google_dn.txt', 'w').write(s)\r\n",
        "\r\n",
        "print(\"\\n\\n=================================\")\r\n",
        "print(\"METHOD:  \", 'GOOGLE')\r\n",
        "print('SL đúng:', dung)\r\n",
        "print('SL sai :', sai)\r\n",
        "print('SL sót :', sot)\r\n",
        "print('Acc    :', dung*100/(dung+sai), '%')\r\n",
        "print('TL sót :', sot*100/(dung+sai), '%')\r\n",
        "print('TL phát hiện     :', 100 - sot*100/(dung+sai), '%')\r\n",
        "print('TL đúng/phát hiện:', dung*100/(dung+sai-sot), '%')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\n",
            "\n",
            "=================================\n",
            "METHOD:   GOOGLE\n",
            "SL đúng: 152\n",
            "SL sai : 204\n",
            "SL sót : 167\n",
            "Acc    : 42.69662921348315 %\n",
            "TL sót : 46.91011235955056 %\n",
            "TL phát hiện     : 53.08988764044944 %\n",
            "TL đúng/phát hiện: 80.42328042328042 %\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nYPJyZ7iZ-kI"
      },
      "source": [
        "## abc"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RouMVHG1iZAr"
      },
      "source": [
        "from spelling_checking import spelling_checking"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "k-6IUdjjkSiX"
      },
      "source": [
        "small_corpus_dir = '/content/drive/My Drive/Colab Notebooks/KLTN_hatespeech/small_corpus1.txt'\n",
        "badwords_dir = '/content/drive/My Drive/Colab Notebooks/KLTN_hatespeech/hate_offensive_vocab.txt'\n",
        "# badwords_dir = '/content/drive/MyDrive/Colab Notebooks/KLTN_hatespeech/temp/word_statistics/hate_offensive_words1.txt'\n",
        "spelling_checking = spelling_checking(\"/content/drive/My Drive/Colab Notebooks/KLTN_hatespeech/Model/skip-gram/\", \"vocab.txt\", \"vec.npy\", small_corpus_dir, badwords_dir, CAND_LIMIT=8 )"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ld2B2Swh_3lE",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "124eea26-2907-4b66-a0c8-c12e9d83281f"
      },
      "source": [
        "spelling_checking.readData()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Done loading vocabulary.\n",
            "Done loading vectors.\n",
            "Corpus length          13509\n",
            "Small corpus length    2069\n",
            "Badwords length        1002\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "91rf3dcJBm9y",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4c46ba0d-a425-47fb-cb11-f4f4637981c0"
      },
      "source": [
        "# test thử 1 câu\n",
        "error_sent_list = [\"đến mấy con nguu bị lừa quay ra chê đàn ông\"]\n",
        "revised_sent_seq, algo_corrections, cand_corrections = spelling_checking.generateAlgoCandCorrection(error_sent_list, 2)\n",
        "print(\"revised sent seq:\")\n",
        "print(revised_sent_seq)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "stage 1\n",
            "done stage 1: raw check on edit distance\n",
            "stage 2.\n",
            "done stage 2: context-dependent check.\n",
            "revised sent seq:\n",
            "[['đến', 'mấy', 'con', 'ngu', 'bị', 'lừa', 'quay', 'ra', 'chê', 'đàn', 'ông']]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_ag-W_LGS3r4"
      },
      "source": [
        "# def loaikitudau(word):\n",
        "#   return word[0] + re.sub('w|s|f|r|x|j', '', word[1:])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CElrUS8eohFy"
      },
      "source": [
        "wrong_sents = processing_data(wrong_hate_offensive_cmts)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uJBuuqHnUAkC"
      },
      "source": [
        "# for i in range(len(wrong_sents)):\n",
        "#   wrong_sents[i] = loaikitudau(wrong_sents[i])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZTKM5qk_n4Zo",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c3c751e2-06cb-4f4b-afd0-14915827fb04"
      },
      "source": [
        "# sửa cho tập train và lưu xuống\n",
        "correct_wrong_sents,_,_ = spelling_checking.generateAlgoCandCorrection(wrong_sents,3)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "stage 1\n",
            "done stage 1: raw check on edit distance\n",
            "stage 2.\n",
            "done stage 2: context-dependent check.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2hxzNW26h7YC"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yHIzK8zfzrx9"
      },
      "source": [
        "temp = []\n",
        "for i in correct_wrong_sents:\n",
        "  temp.append(' '.join(i))\n",
        "correct_wrong_sents = temp"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "x0qETgZOlkHy",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8ed3a1d8-8c91-4a49-e647-a35022004dd0"
      },
      "source": [
        "dung = 0\n",
        "sai = 0\n",
        "sot = 0\n",
        "s = ''\n",
        "for index, i in enumerate(correct_wrong_sents):\n",
        "  i = i.split()\n",
        "  # if correct_words[index] in i:\n",
        "  if set(correct_words[index]) & set(i) != set():\n",
        "    dung +=1\n",
        "    s = (s  + 'ĐÚNG\\n'\n",
        "            + 'Từ sai:  ' + wrong_words[index] + '\\t Từ gốc: ' +  '_'.join(correct_words[index]) + '\\n'\n",
        "            + 'Câu sửa: ' + correct_wrong_sents[index] + '\\n'\n",
        "            + 'Câu gốc: ' + hate_offensive_cmts[index] + '\\n'\n",
        "            + 'Câu sai: ' + wrong_hate_offensive_cmts[index] + '\\n'\n",
        "            + '----------------------------\\n\\n')\n",
        "    # if (wrong_words[index] not in wrong_hate_offensive_cmts[index].split()[0]):\n",
        "    #   print('Từ sai: ', wrong_words[index],'\\t Từ gốc:', correct_words[index])\n",
        "    #   print('Câu sửa:',correct_wrong_sents[index])\n",
        "    #   print('Câu gốc:',hate_offensive_cmts[index])\n",
        "    #   print('Câu sai:',wrong_hate_offensive_cmts[index])\n",
        "    #   print('\\n\\n')\n",
        "  else:\n",
        "    sai += 1\n",
        "    s = s + 'SAI'\n",
        "    print(\"SAI\")\n",
        "    if wrong_words[index] in i:\n",
        "      sot += 1 \n",
        "      s = s + ' SÓT'\n",
        "      print('SÓT')\n",
        "    s = (s  + '\\n'\n",
        "            + 'Từ sai:  ' + wrong_words[index] + '\\t Từ gốc: ' +  '_'.join(correct_words[index]) + '\\n'\n",
        "            + 'Câu sửa: ' + correct_wrong_sents[index] + '\\n'\n",
        "            + 'Câu gốc: ' + hate_offensive_cmts[index] + '\\n'\n",
        "            + 'Câu sai: ' + wrong_hate_offensive_cmts[index] + '\\n'\n",
        "            + '----------------------------\\n\\n')\n",
        "      \n",
        "      \n",
        "\n",
        "    print('Từ sai:', wrong_words[index],'\\t Từ gốc:', correct_words[index])\n",
        "    print('Câu sửa:',correct_wrong_sents[index])\n",
        "    print('Câu gốc:',hate_offensive_cmts[index])\n",
        "    print('Câu sai:',wrong_hate_offensive_cmts[index])\n",
        "    print('\\n\\n')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "SAI\n",
            "Từ sai: nguuu \t Từ gốc: ['ngu']\n",
            "Câu sửa: phân tích dài vl xúc tích mỗi tội nguu vl\n",
            "Câu gốc: phân tích dài vl xúc tích mỗi tội ngu vl\n",
            "Câu sai: phân tích dài vl xúc tích mỗi tội nguuu vl\n",
            "\n",
            "\n",
            "\n",
            "SAI\n",
            "Từ sai: lws \t Từ gốc: ['lũ']\n",
            "Câu sửa: nguyễn cao trọng nói này cái gì mấy đứa xàm có trên báo ngta nói là ngu dân\n",
            "Câu gốc: nguyễn cao trọng nói này cái gì mấy đứa xàm có trên báo ngta nói lũ ngu dân\n",
            "Câu sai: nguyễn cao trọng nói này cái gì mấy đứa xàm có trên báo ngta nói lws ngu dân\n",
            "\n",
            "\n",
            "\n",
            "SAI\n",
            "Từ sai: vsl \t Từ gốc: ['vl']\n",
            "Câu sửa: prince phùng bảo sao lấy xấu vkl\n",
            "Câu gốc: prince phùng bảo sao lấy xấu vl\n",
            "Câu sai: prince phùng bảo sao lấy xấu vsl\n",
            "\n",
            "\n",
            "\n",
            "SAI\n",
            "Từ sai: vsl \t Từ gốc: ['vl']\n",
            "Câu sửa: ad thâm dái vcl\n",
            "Câu gốc: ad thâm dái vl\n",
            "Câu sai: ad thâm dái vsl\n",
            "\n",
            "\n",
            "\n",
            "SAI\n",
            "Từ sai: đkó \t Từ gốc: ['đó']\n",
            "Câu sửa: lê thị ngọc tuyền đkm vailon\n",
            "Câu gốc: lê thị ngọc tuyền đó condilon\n",
            "Câu sai: lê thị ngọc tuyền đkó condilon\n",
            "\n",
            "\n",
            "\n",
            "SAI\n",
            "SÓT\n",
            "Từ sai: cutt \t Từ gốc: ['cút']\n",
            "Câu sửa: xin nhắc lại nếu đã là bạn bè chơi với nhau thì đừng khinh thường nhau còn nếu đã ko tôn trọng nhau thì cutt hộ tao tao cũng đéo cần\n",
            "Câu gốc: xin nhắc lại nếu đã là bạn bè chơi với nhau thì đừng khinh thường nhau còn nếu đã ko tôn trọng nhau thì cút hộ tao tao cũng đéo cần\n",
            "Câu sai: xin nhắc lại nếu đã là bạn bè chơi với nhau thì đừng khinh thường nhau còn nếu đã ko tôn trọng nhau thì cutt hộ tao tao cũng đéo cần\n",
            "\n",
            "\n",
            "\n",
            "SAI\n",
            "Từ sai: vlm \t Từ gốc: ['vl']\n",
            "Câu sửa: mông to xấu clm\n",
            "Câu gốc: mông to xấu vl\n",
            "Câu sai: mông to xấu vlm\n",
            "\n",
            "\n",
            "\n",
            "SAI\n",
            "Từ sai: nguuu \t Từ gốc: ['ngu']\n",
            "Câu sửa: dốt me con my lam bo deo nguu dc\n",
            "Câu gốc: dit me con my lam bo deo ngu dc\n",
            "Câu sai: dit me con my lam bo deo nguuu dc\n",
            "\n",
            "\n",
            "\n",
            "SAI\n",
            "SÓT\n",
            "Từ sai: ul \t Từ gốc: ['vl']\n",
            "Câu sửa: bảo my th ngáo này cũng hay ul kk\n",
            "Câu gốc: bảo my th ngáo này cũng hay vl kk\n",
            "Câu sai: bảo my th ngáo này cũng hay ul kk\n",
            "\n",
            "\n",
            "\n",
            "SAI\n",
            "Từ sai: màý \t Từ gốc: ['mày']\n",
            "Câu sửa: nam tô không nói có lẽ ko ai biết mà ngu đâu\n",
            "Câu gốc: nam tô không nói có lẽ ko ai biết mày ngu đâu\n",
            "Câu sai: nam tô không nói có lẽ ko ai biết màý ngu đâu\n",
            "\n",
            "\n",
            "\n",
            "SAI\n",
            "Từ sai: cmtn \t Từ gốc: ['cmt']\n",
            "Câu sửa: xin phép xoá cmn bệnh hoạn vl\n",
            "Câu gốc: xin phép xoá cmt bệnh hoạn vl\n",
            "Câu sai: xin phép xoá cmtn bệnh hoạn vl\n",
            "\n",
            "\n",
            "\n",
            "SAI\n",
            "Từ sai: lòz \t Từ gốc: ['lồn']\n",
            "Câu sửa: che che cái me lz cay vl\n",
            "Câu gốc: che che cái me lồn cay vl\n",
            "Câu sai: che che cái me lòz cay vl\n",
            "\n",
            "\n",
            "\n",
            "SAI\n",
            "Từ sai: oć \t Từ gốc: ['óc']\n",
            "Câu sửa: vu tran đúng là có chó chỉ đưa ra câu hỏi bị hỏi lại thì cứng cmn họng xong lại hỏi câu khác ngu thì câm cái mõm lại để người khác đỡ chửi mình ngu nhé\n",
            "Câu gốc: vu tran đúng là óc chó chỉ đưa ra câu hỏi bị hỏi lại thì cứng cmn họng xong lại hỏi câu khác ngu thì câm cái mõm lại để người khác đỡ chửi mình ngu nhé\n",
            "Câu sai: vu tran đúng là oć chó chỉ đưa ra câu hỏi bị hỏi lại thì cứng cmn họng xong lại hỏi câu khác ngu thì câm cái mõm lại để người khác đỡ chửi mình ngu nhé\n",
            "\n",
            "\n",
            "\n",
            "SAI\n",
            "Từ sai: đ.mẹ \t Từ gốc: ['đm']\n",
            "Câu sửa: mẹ mấy thằng trộm chúng hay lắm bố vớ đc thì xác định đi lấy đt bố mày mấy con chó\n",
            "Câu gốc: đm mấy thằng trộm chúng hay lắm bố vớ đc thì xác định đi lấy đt bố mày mấy con chó\n",
            "Câu sai: đ.mẹ mấy thằng trộm chúng hay lắm bố vớ đc thì xác định đi lấy đt bố mày mấy con chó\n",
            "\n",
            "\n",
            "\n",
            "SAI\n",
            "Từ sai: màý \t Từ gốc: ['mày']\n",
            "Câu sửa: bộ mà bị đui hả chủ xe cái đã sáng gắn bao nhiêu đó mù mắt người đi ngược chiều ngu như chó\n",
            "Câu gốc: bộ mày bị đui hả chủ xe cái đã sáng gắn bao nhiêu đó mù mắt người đi ngược chiều ngu như chó\n",
            "Câu sai: bộ màý bị đui hả chủ xe cái đã sáng gắn bao nhiêu đó mù mắt người đi ngược chiều ngu như chó\n",
            "\n",
            "\n",
            "\n",
            "SAI\n",
            "Từ sai: cưst \t Từ gốc: ['cứt']\n",
            "Câu sửa: ủa ông cố nội ngta hả mà cho coi trường giang dẫn ct như chết ăn nói vô duyên suốt ngày móc méo đá xoáy ng khác chã có kiến thức chuyên môn cmn bây còn chả thèm diễn hài mà làm mc luôn mặc dù nc vô duyên vcl ra\n",
            "Câu gốc: ủa ông cố nội ngta hả mà cho coi trường giang dẫn ct như cứt ăn nói vô duyên suốt ngày móc méo đá xoáy ng khác chã có kiến thức chuyên môn cmg bây còn chả thèm diễn hài mà làm mc luôn mặc dù nc vô duyên vcl ra\n",
            "Câu sai: ủa ông cố nội ngta hả mà cho coi trường giang dẫn ct như cưst ăn nói vô duyên suốt ngày móc méo đá xoáy ng khác chã có kiến thức chuyên môn cmg bây còn chả thèm diễn hài mà làm mc luôn mặc dù nc vô duyên vcl ra\n",
            "\n",
            "\n",
            "\n",
            "SAI\n",
            "Từ sai: màý \t Từ gốc: ['mày']\n",
            "Câu sửa: mà khôn lắm thằng ngu\n",
            "Câu gốc: mày khôn lắm thằng ngu\n",
            "Câu sai: màý khôn lắm thằng ngu\n",
            "\n",
            "\n",
            "\n",
            "SAI\n",
            "SÓT\n",
            "Từ sai: lud \t Từ gốc: ['lũ']\n",
            "Câu sửa: xã hội thì không thể bảo vệ được tính mang người lái xe nhưng người ta lắp thiết bị để tự bảo vệ lấy mạng sống của mình thì bị chúng nó phạt một lud lãnh đạo mạt hạng ngu truyền kiếp\n",
            "Câu gốc: xã hội thì không thể bảo vệ được tính mang người lái xe nhưng người ta lắp thiết bị để tự bảo vệ lấy mạng sống của mình thì bị chúng nó phạt một lũ lãnh đạo mạt hạng ngu truyền kiếp\n",
            "Câu sai: xã hội thì không thể bảo vệ được tính mang người lái xe nhưng người ta lắp thiết bị để tự bảo vệ lấy mạng sống của mình thì bị chúng nó phạt một lud lãnh đạo mạt hạng ngu truyền kiếp\n",
            "\n",
            "\n",
            "\n",
            "SAI\n",
            "Từ sai: dmk \t Từ gốc: ['đm']\n",
            "Câu sửa: dm ăn rồi thì nuốt luôn đi còn ỏi ra làm gì ói ra cho cha mẹ mày ăn hả thằng tt bị mắc nghẹn\n",
            "Câu gốc: đm ăn rồi thì nuốt luôn đi còn ỏi ra làm gì ói ra cho cha mẹ mày ăn hả thầng tt bị mắc nghẹn\n",
            "Câu sai: dmk ăn rồi thì nuốt luôn đi còn ỏi ra làm gì ói ra cho cha mẹ mày ăn hả thầng tt bị mắc nghẹn\n",
            "\n",
            "\n",
            "\n",
            "SAI\n",
            "Từ sai: maạy \t Từ gốc: ['mày']\n",
            "Câu sửa: thế may nghỉ là gì chả như nói dân óc chó\n",
            "Câu gốc: thế mày nghỉ là gì chả nhẻ nói dân óc chó\n",
            "Câu sai: thế maạy nghỉ là gì chả nhẻ nói dân óc chó\n",
            "\n",
            "\n",
            "\n",
            "SAI\n",
            "Từ sai: mạy \t Từ gốc: ['mày']\n",
            "Câu sửa: cứ nhất thiết phải phát ngôn cho người khác biết may ngu\n",
            "Câu gốc: cứ nhất thiết phải phát ngôn cho người khác biết mày ngu\n",
            "Câu sai: cứ nhất thiết phải phát ngôn cho người khác biết mạy ngu\n",
            "\n",
            "\n",
            "\n",
            "SAI\n",
            "Từ sai: đ.mẹ \t Từ gốc: ['đm']\n",
            "Câu sửa: đmm nó giả vờ đấy thằng ngu ak\n",
            "Câu gốc: đm nó giả vờ đấy thằng ngu ak\n",
            "Câu sai: đ.mẹ nó giả vờ đấy thằng ngu ak\n",
            "\n",
            "\n",
            "\n",
            "SAI\n",
            "Từ sai: occ \t Từ gốc: ['óc']\n",
            "Câu sửa: phương mai del nói vcc chó del biết tưởng thích chó ngu vc\n",
            "Câu gốc: phương mai del nói óc chó del biết tưởng thích chó ngu vc\n",
            "Câu sai: phương mai del nói occ chó del biết tưởng thích chó ngu vc\n",
            "\n",
            "\n",
            "\n",
            "SAI\n",
            "Từ sai: df \t Từ gốc: ['di']\n",
            "Câu sửa: thang gia to ba khon nan qua dm\n",
            "Câu gốc: thang gia toc bac khon nan qua di\n",
            "Câu sai: thang gia toc bac khon nan qua df\n",
            "\n",
            "\n",
            "\n",
            "SAI\n",
            "Từ sai: đỹ \t Từ gốc: ['đĩ']\n",
            "Câu sửa: ngọc ngân làm để có có học toán để tính tiền đi khách hoá để xem khách có dùng chất hoá học học văn để gọi khách\n",
            "Câu gốc: ngọc ngân làm đĩ cx có học toán để tính tiền đi khách hoá để xem khách có dùng chất hoá học học văn để gọi khách\n",
            "Câu sai: ngọc ngân làm đỹ cx có học toán để tính tiền đi khách hoá để xem khách có dùng chất hoá học học văn để gọi khách\n",
            "\n",
            "\n",
            "\n",
            "SAI\n",
            "Từ sai: vul \t Từ gốc: ['vl']\n",
            "Câu sửa: tự hào châu nghe ngứa dái vkl\n",
            "Câu gốc: tự hào châu nghe ngứa dái vl\n",
            "Câu sai: tự hào châu nghe ngứa dái vul\n",
            "\n",
            "\n",
            "\n",
            "SAI\n",
            "Từ sai: đ.mẹ \t Từ gốc: ['đm']\n",
            "Câu sửa: đmm ông về mà bán vé số đi cuồng ngôn\n",
            "Câu gốc: đm ông về mà bán vé số đi cuồng ngôn\n",
            "Câu sai: đ.mẹ ông về mà bán vé số đi cuồng ngôn\n",
            "\n",
            "\n",
            "\n",
            "SAI\n",
            "Từ sai: vxl \t Từ gốc: ['vl']\n",
            "Câu sửa: sao có mấy con ngộ ghê tự nhiên kh phải thùy kh xem mu ủa ngộ nghĩnh nhỉ kh xem thì thôi nói ra chi vậy thể hiện vkl\n",
            "Câu gốc: sao có mấy con ngộ ghê tự nhiên kh phải thùy kh xem mu ủa ngộ nghĩnh nhỉ kh xem thì thôi nói ra chi vậy thể hiện vl\n",
            "Câu sai: sao có mấy con ngộ ghê tự nhiên kh phải thùy kh xem mu ủa ngộ nghĩnh nhỉ kh xem thì thôi nói ra chi vậy thể hiện vxl\n",
            "\n",
            "\n",
            "\n",
            "SAI\n",
            "Từ sai: đijt \t Từ gốc: ['địt']\n",
            "Câu sửa: biết thế ngày xưa biết mẹ để mẹ rát lồn đẻ ra thằng óc chó như\n",
            "Câu gốc: biết thế ngày xưa địt mẹ để mẹ rát lồn đẻ ra thằng óc chó như\n",
            "Câu sai: biết thế ngày xưa đijt mẹ để mẹ rát lồn đẻ ra thằng óc chó như\n",
            "\n",
            "\n",
            "\n",
            "SAI\n",
            "Từ sai: lòz \t Từ gốc: ['lol']\n",
            "Câu sửa: ủa bộ rồi đứa nào cũng như đứa nào ad nứng lz hả\n",
            "Câu gốc: ủa bộ rồi đứa nào cũng như đứa nào ad nứng lol hả\n",
            "Câu sai: ủa bộ rồi đứa nào cũng như đứa nào ad nứng lòz hả\n",
            "\n",
            "\n",
            "\n",
            "SAI\n",
            "Từ sai: occ \t Từ gốc: ['óc']\n",
            "Câu sửa: vcc chó mày đi ăn cứt bọn tàu khựa đi mày nhà mày ngu có gia phả rồi hả mày\n",
            "Câu gốc: óc chó mày đi ăn cứt bọn tàu khựa đi mày nhà mày ngu có gia phả rồi hả mày\n",
            "Câu sai: occ chó mày đi ăn cứt bọn tàu khựa đi mày nhà mày ngu có gia phả rồi hả mày\n",
            "\n",
            "\n",
            "\n",
            "SAI\n",
            "Từ sai: eó \t Từ gốc: ['éo']\n",
            "Câu sửa: mình cứ nghi cho ng ta cuối cùng mình mới hiểu ra rằng ngta ích kỷ có nghĩ đến minh thôi đến đâu thì đến thảo nhi is exhausted\n",
            "Câu gốc: mình cứ nghi cho ng ta cuôi cùng mình mới hiểu ra rằng nta ích kỷ éo nghĩ đến minh thôi đến đâu thì đến thảo nhi is  exhausted\n",
            "Câu sai: mình cứ nghi cho ng ta cuôi cùng mình mới hiểu ra rằng nta ích kỷ eó nghĩ đến minh thôi đến đâu thì đến thảo nhi is exhausted\n",
            "\n",
            "\n",
            "\n",
            "SAI\n",
            "Từ sai: maạy \t Từ gốc: ['mày']\n",
            "Câu sửa: ghét tao hả dm kệ mẹ may làm loz gì tao\n",
            "Câu gốc: ghét tao hả ừm kệ mẹ mày làm loz gì tao\n",
            "Câu sai: ghét tao hả ừm kệ mẹ maạy làm loz gì tao\n",
            "\n",
            "\n",
            "\n",
            "SAI\n",
            "Từ sai: lws \t Từ gốc: ['lũ']\n",
            "Câu sửa: là chó chết trung quốc chúng bay gian tham độc ác ăn cướp còn già mồm đứng là loại chó chết\n",
            "Câu gốc: lũ chó chết trung quốc chúng bay gian tham độc ác ăn cướp còn già mồm đứng là loại chó chết\n",
            "Câu sai: lws chó chết trung quốc chúng bay gian tham độc ác ăn cướp còn già mồm đứng là loại chó chết\n",
            "\n",
            "\n",
            "\n",
            "SAI\n",
            "Từ sai: vcq \t Từ gốc: ['vcl']\n",
            "Câu sửa: bú fame lố vcc\n",
            "Câu gốc: bú fame lố vcl\n",
            "Câu sai: bú fame lố vcq\n",
            "\n",
            "\n",
            "\n",
            "SAI\n",
            "Từ sai: thawng \t Từ gốc: ['thằng']\n",
            "Câu sửa: thang chó muốn giết dân\n",
            "Câu gốc: thằng chó muốn giết dân\n",
            "Câu sai: thawng chó muốn giết dân\n",
            "\n",
            "\n",
            "\n",
            "SAI\n",
            "Từ sai: maạy \t Từ gốc: ['mày']\n",
            "Câu sửa: nguyễn văn độ may thằng trộm chó đéo chấp\n",
            "Câu gốc: nguyễn văn độ mày thằng trộm chó đéo chấp\n",
            "Câu sai: nguyễn văn độ maạy thằng trộm chó đéo chấp\n",
            "\n",
            "\n",
            "\n",
            "SAI\n",
            "Từ sai: ltại \t Từ gốc: ['lại']\n",
            "Câu sửa: loại tha hồ vơ vét nhét đầy túi ôi cộng sản\n",
            "Câu gốc: lại tha hồ vơ vét nhét đầy túi ôi cộng sản\n",
            "Câu sai: ltại tha hồ vơ vét nhét đầy túi ôi cộng sản\n",
            "\n",
            "\n",
            "\n",
            "SAI\n",
            "Từ sai: thawng \t Từ gốc: ['thằng']\n",
            "Câu sửa: minh quang chỉ cần có cái chân cứng thang nào tao cũng đéo ngán\n",
            "Câu gốc: minh quang chỉ cần có cái chân cứng thằng nào tao cũng đéo ngán\n",
            "Câu sai: minh quang chỉ cần có cái chân cứng thawng nào tao cũng đéo ngán\n",
            "\n",
            "\n",
            "\n",
            "SAI\n",
            "SÓT\n",
            "Từ sai: chửy \t Từ gốc: ['chửi']\n",
            "Câu sửa: xe vô cảng ra khỏi cảng đã chửy lộn hết người chứ không thì nha anh anh thông cảm bà cha ai thông cảm cho ops ai thông cảm cho tài xế con nữa rớt lại luôn không thể nào cứu chữa\n",
            "Câu gốc: xe vô cảng ra khỏi cảng đã chửi lộn hết người chứ không thì nha anh anh thông cảm bà cha ai thông cảm cho ops ai thông cảm cho tài xế cont nữa rớt lại luôn không thể nào cứu chữa \n",
            "Câu sai: xe vô cảng ra khỏi cảng đã chửy lộn hết người chứ không thì nha anh anh thông cảm bà cha ai thông cảm cho ops ai thông cảm cho tài xế cont nữa rớt lại luôn không thể nào cứu chữa\n",
            "\n",
            "\n",
            "\n",
            "SAI\n",
            "Từ sai: cứk \t Từ gốc: ['cứt']\n",
            "Câu sửa: từ hôm qua đến giờ vẫn chưa tiêu hóa đc cái cục cay này cức đái thật khánh khoa nt is motivated\n",
            "Câu gốc: từ hôm qua đến giờ vẫn chưa tiêu hóa đc cái cục cay này cứt đái thật khánh khoa nt is  motivated\n",
            "Câu sai: từ hôm qua đến giờ vẫn chưa tiêu hóa đc cái cục cay này cứk đái thật khánh khoa nt is motivated\n",
            "\n",
            "\n",
            "\n",
            "SAI\n",
            "Từ sai: đci \t Từ gốc: ['đi']\n",
            "Câu sửa: nên biết thân biết phận xíu đc đồ cho\n",
            "Câu gốc: nên biêt thân biết phận xíu đi đồ chossss\n",
            "Câu sai: nên biêt thân biết phận xíu đci đồ chossss\n",
            "\n",
            "\n",
            "\n",
            "SAI\n",
            "Từ sai: đmmm \t Từ gốc: ['đm']\n",
            "Câu sửa: đmm cay vl nguyễn văn hùng is depressed\n",
            "Câu gốc: đm cay vl nguyễn văn hùng is  depressed\n",
            "Câu sai: đmmm cay vl nguyễn văn hùng is depressed\n",
            "\n",
            "\n",
            "\n",
            "SAI\n",
            "Từ sai: rl \t Từ gốc: ['vl']\n",
            "Câu sửa: chơi game với mấy người như vậy ức chế ra\n",
            "Câu gốc: chơi game với mấy người như vậy ức chế vl\n",
            "Câu sai: chơi game với mấy người như vậy ức chế rl\n",
            "\n",
            "\n",
            "\n",
            "SAI\n",
            "Từ sai: đỹ \t Từ gốc: ['đĩ']\n",
            "Câu sửa: đm mẹ đúng vl\n",
            "Câu gốc: đĩ mẹ đúng vl\n",
            "Câu sai: đỹ mẹ đúng vl\n",
            "\n",
            "\n",
            "\n",
            "SAI\n",
            "Từ sai: hàc \t Từ gốc: ['hài']\n",
            "Câu sửa: dcm hào hước\n",
            "Câu gốc: dcm hài hước\n",
            "Câu sai: dcm hàc hước\n",
            "\n",
            "\n",
            "\n",
            "SAI\n",
            "Từ sai: ngz \t Từ gốc: ['ngu']\n",
            "Câu sửa: thảo vy mẹ nc ngô vl\n",
            "Câu gốc: thảo vy mẹ nch ngu vl\n",
            "Câu sai: thảo vy mẹ nch ngz vl\n",
            "\n",
            "\n",
            "\n",
            "SAI\n",
            "Từ sai: nva \t Từ gốc: ['nữa']\n",
            "Câu sửa: hồng hồng mới đẻ xong đi cm dạo na ha khỏe zô kk\n",
            "Câu gốc: hồng hồng mới đẻ xong đi cm dạo nữa ha khỏe zữ kkk\n",
            "Câu sai: hồng hồng mới đẻ xong đi cm dạo nva ha khỏe zữ kkk\n",
            "\n",
            "\n",
            "\n",
            "SAI\n",
            "Từ sai: xm \t Từ gốc: ['dm']\n",
            "Câu sửa: xe tát thông báo nên quên\n",
            "Câu gốc: dm tát thông báo nên quên\n",
            "Câu sai: xm tát thông báo nên quên\n",
            "\n",
            "\n",
            "\n",
            "SAI\n",
            "Từ sai: hàa \t Từ gốc: ['hài']\n",
            "Câu sửa: hồng ngát dm cứu hoa vl\n",
            "Câu gốc: hồng ngát dm cứu hài vl\n",
            "Câu sai: hồng ngát dm cứu hàa vl\n",
            "\n",
            "\n",
            "\n",
            "SAI\n",
            "SÓT\n",
            "Từ sai: wl \t Từ gốc: ['vl']\n",
            "Câu sửa: vếu căng wl\n",
            "Câu gốc: vếu căng vl\n",
            "Câu sai: vếu căng wl\n",
            "\n",
            "\n",
            "\n",
            "SAI\n",
            "SÓT\n",
            "Từ sai: đmá \t Từ gốc: ['đm']\n",
            "Câu sửa: đmá vl\n",
            "Câu gốc: đm vl\n",
            "Câu sai: đmá vl\n",
            "\n",
            "\n",
            "\n",
            "SAI\n",
            "Từ sai: sl \t Từ gốc: ['vl']\n",
            "Câu sửa: an nhiên dm buồn ỉa chạy vấp vào gà cái là tắc ỉa ám ảnh tuổi thơ số\n",
            "Câu gốc: an nhiên dg buồn ỉa chạy vấp vào gà cái là tắc ỉa ám ảnh tuổi thơ vl\n",
            "Câu sai: an nhiên dg buồn ỉa chạy vấp vào gà cái là tắc ỉa ám ảnh tuổi thơ sl\n",
            "\n",
            "\n",
            "\n",
            "SAI\n",
            "Từ sai: đjit \t Từ gốc: ['địt']\n",
            "Câu sửa: chỉ cần bà may qua được khoảng thời gian này thôi thì đời mẹ mày đời mày tuổi loz\n",
            "Câu gốc: chỉ cần bà may qua được khoảng thời gian này thôi thì địt mẹ mày đời mày tuổi loz \n",
            "Câu sai: chỉ cần bà may qua được khoảng thời gian này thôi thì đjit mẹ mày đời mày tuổi loz\n",
            "\n",
            "\n",
            "\n",
            "SAI\n",
            "Từ sai: fcl \t Từ gốc: ['vcl']\n",
            "Câu sửa: cl\n",
            "Câu gốc: vcl\n",
            "Câu sai: fcl\n",
            "\n",
            "\n",
            "\n",
            "SAI\n",
            "Từ sai: vwl \t Từ gốc: ['vl']\n",
            "Câu sửa: qua tài cao vcl\n",
            "Câu gốc: duma tài cao vl\n",
            "Câu sai: duma tài cao vwl\n",
            "\n",
            "\n",
            "\n",
            "SAI\n",
            "Từ sai: đ.mẹ \t Từ gốc: ['đm']\n",
            "Câu sửa: mẹ cả đứa mới sợ vl\n",
            "Câu gốc: đm cả đứa  mới sợ vl\n",
            "Câu sai: đ.mẹ cả đứa mới sợ vl\n",
            "\n",
            "\n",
            "\n",
            "SAI\n",
            "Từ sai: yoy \t Từ gốc: ['you']\n",
            "Câu sửa: con sút đai đu choá\n",
            "Câu gốc: you sút đai đuỹ choá\n",
            "Câu sai: yoy sút đai đuỹ choá\n",
            "\n",
            "\n",
            "\n",
            "SAI\n",
            "SÓT\n",
            "Từ sai: hamx \t Từ gốc: ['hãm']\n",
            "Câu sửa: mặt phồng hamx vl\n",
            "Câu gốc: mặt phồng hãm vl\n",
            "Câu sai: mặt phồng hamx vl\n",
            "\n",
            "\n",
            "\n",
            "SAI\n",
            "Từ sai: eó \t Từ gốc: ['éo']\n",
            "Câu sửa: vũ hoàng trung hơ ai đó bớt sĩ diện lại thì ok còn ko có\n",
            "Câu gốc: vũ hoàng trung hơ ai đó bớt sĩ diện lại thì ok còn ko éo \n",
            "Câu sai: vũ hoàng trung hơ ai đó bớt sĩ diện lại thì ok còn ko eó\n",
            "\n",
            "\n",
            "\n",
            "SAI\n",
            "Từ sai: nɥu \t Từ gốc: ['ngu']\n",
            "Câu sửa: lúc đó chơi nếu vl\n",
            "Câu gốc: lúc đó chơi ngu vl\n",
            "Câu sai: lúc đó chơi nɥu vl\n",
            "\n",
            "\n",
            "\n",
            "SAI\n",
            "SÓT\n",
            "Từ sai: jl \t Từ gốc: ['vl']\n",
            "Câu sửa: má cá chiên ngon jl\n",
            "Câu gốc: má cá chiên ngon vl\n",
            "Câu sai: má cá chiên ngon jl\n",
            "\n",
            "\n",
            "\n",
            "SAI\n",
            "Từ sai: vvl \t Từ gốc: ['vl']\n",
            "Câu sửa: má phính ghê vcl\n",
            "Câu gốc: má phính ghê vl\n",
            "Câu sai: má phính ghê vvl\n",
            "\n",
            "\n",
            "\n",
            "SAI\n",
            "Từ sai: eoi \t Từ gốc: ['éo']\n",
            "Câu sửa: không kết hôn còn hp hơn lúc yêu hứa thề như đúng rồi như có đc rồi thì tất cả chỉ là xàm thôi noi tin dc lũ đàn ông\n",
            "Câu gốc: không kết hôn còn hp hơn lúc yêu hứa thề như đúng rồi như có đc rồi thì tất cả chỉ là xàm thôi éo tin dc lũ đàn ông\n",
            "Câu sai: không kết hôn còn hp hơn lúc yêu hứa thề như đúng rồi như có đc rồi thì tất cả chỉ là xàm thôi eoi tin dc lũ đàn ông\n",
            "\n",
            "\n",
            "\n",
            "SAI\n",
            "Từ sai: boṇ \t Từ gốc: ['bọn']\n",
            "Câu sửa: cục xì lầu ong bê nắp nhà mình nghèo đi xe bus kệ mẹ con đi xe khách đầm già xì gặp quy ka át cả nhà mày bị phong tê thấp bò một sừng là con tê giác thằng luân là con tê giác thằng luân nhiều sừng hơn con tê giác hoàng lộc is thành luân\n",
            "Câu gốc: cục xì lầu ong bê nắp nhà mình nghèo đi xe bus kệ mẹ bọn đi xe khách đầm già xì gặp quy ka át cả nhà mày bị phong tê thấp bò một sừng là con tê giác thằng luân là con tê giác thằng luân nhiều sừng hơn con tê giác hoàng lộc is  thành luân\n",
            "Câu sai: cục xì lầu ong bê nắp nhà mình nghèo đi xe bus kệ mẹ boṇ đi xe khách đầm già xì gặp quy ka át cả nhà mày bị phong tê thấp bò một sừng là con tê giác thằng luân là con tê giác thằng luân nhiều sừng hơn con tê giác hoàng lộc is thành luân\n",
            "\n",
            "\n",
            "\n",
            "SAI\n",
            "Từ sai: cqó \t Từ gốc: ['có']\n",
            "Câu sửa: cà chua chó cười ỉa\n",
            "Câu gốc: cà chua có cười ỉa\n",
            "Câu sai: cà chua cqó cười ỉa\n",
            "\n",
            "\n",
            "\n",
            "SAI\n",
            "Từ sai: đmmm \t Từ gốc: ['đm']\n",
            "Câu sửa: phương rô đmm giống vl\n",
            "Câu gốc: phương rô đm giống vl\n",
            "Câu sai: phương rô đmmm giống vl\n",
            "\n",
            "\n",
            "\n",
            "SAI\n",
            "Từ sai: dỵt \t Từ gốc: ['địt']\n",
            "Câu sửa: lấy ai dốt mẹ các em nghĩ lấy vợ như ra chợ nhặt mớ rau đéo có gì ăn thì ra nhặt tạm\n",
            "Câu gốc: lấy ai địt mẹ các em nghĩ lấy vợ như ra chợ nhặt mớ rau đéo có gì ăn thì ra nhặt tạm \n",
            "Câu sai: lấy ai dỵt mẹ các em nghĩ lấy vợ như ra chợ nhặt mớ rau đéo có gì ăn thì ra nhặt tạm\n",
            "\n",
            "\n",
            "\n",
            "SAI\n",
            "Từ sai: đ.má \t Từ gốc: ['đm']\n",
            "Câu sửa: đmm mình bản lĩnh vl\n",
            "Câu gốc: đm mình bản lĩnh vl\n",
            "Câu sai: đ.má mình bản lĩnh vl\n",
            "\n",
            "\n",
            "\n",
            "SAI\n",
            "Từ sai: vw \t Từ gốc: ['vl']\n",
            "Câu sửa: nhạc nghe bắt tai và\n",
            "Câu gốc: nhạc nghe bắt tai vl\n",
            "Câu sai: nhạc nghe bắt tai vw\n",
            "\n",
            "\n",
            "\n",
            "SAI\n",
            "Từ sai: cjo \t Từ gốc: ['cho']\n",
            "Câu sửa: dm ngu ngoai thi co chết luôn di\n",
            "Câu gốc: dm neu ngoai tih cho chết luôn di\n",
            "Câu sai: dm neu ngoai tih cjo chết luôn di\n",
            "\n",
            "\n",
            "\n",
            "SAI\n",
            "Từ sai: đ.má \t Từ gốc: ['đm']\n",
            "Câu sửa: đmm chuẩn soái ca vl\n",
            "Câu gốc: đm chuẩn soái ca vl\n",
            "Câu sai: đ.má chuẩn soái ca vl\n",
            "\n",
            "\n",
            "\n",
            "SAI\n",
            "Từ sai: đme \t Từ gốc: ['đm']\n",
            "Câu sửa: đmm nhanh gọn vl\n",
            "Câu gốc: đm nhanh gọn vl\n",
            "Câu sai: đme nhanh gọn vl\n",
            "\n",
            "\n",
            "\n",
            "SAI\n",
            "Từ sai: đmmm \t Từ gốc: ['đm']\n",
            "Câu sửa: trang nhỏ đmm thề nhìn ảnh này xong nhìn ảnh bìa bực vl\n",
            "Câu gốc: trang nhỏ đm thề nhìn ảnh này xong nhìn ảnh bìa bực vl\n",
            "Câu sai: trang nhỏ đmmm thề nhìn ảnh này xong nhìn ảnh bìa bực vl\n",
            "\n",
            "\n",
            "\n",
            "SAI\n",
            "Từ sai: eó \t Từ gốc: ['éo']\n",
            "Câu sửa: lớp tao có có ai để để cả ngoài cô giáo chủ nhiệm\n",
            "Câu gốc: lớp tao éo có ai để để cả ngoài cô giáo chủ nhiệm\n",
            "Câu sai: lớp tao eó có ai để để cả ngoài cô giáo chủ nhiệm\n",
            "\n",
            "\n",
            "\n",
            "SAI\n",
            "Từ sai: đmmm \t Từ gốc: ['đm']\n",
            "Câu sửa: đmm ám ảnh vl\n",
            "Câu gốc: đm ám ảnh vl\n",
            "Câu sai: đmmm ám ảnh vl\n",
            "\n",
            "\n",
            "\n",
            "SAI\n",
            "Từ sai: nód \t Từ gốc: ['nó']\n",
            "Câu sửa: nói hay giận vl đang giận này lâu hết vl đmm\n",
            "Câu gốc: nó hay giận vl đang giận này lâu hết vl hmmm\n",
            "Câu sai: nód hay giận vl đang giận này lâu hết vl hmmm\n",
            "\n",
            "\n",
            "\n",
            "SAI\n",
            "Từ sai: mạy \t Từ gốc: ['mày']\n",
            "Câu sửa: nói bao lần rồi tao ko phải mẹ chúng may nát hết vú tao rồi huhuu\n",
            "Câu gốc: nói bao lần rồi tao ko phải mẹ chúng mày nát hết vú tao rồi huhuu \n",
            "Câu sai: nói bao lần rồi tao ko phải mẹ chúng mạy nát hết vú tao rồi huhuu\n",
            "\n",
            "\n",
            "\n",
            "SAI\n",
            "Từ sai: cit \t Từ gốc: ['dit']\n",
            "Câu sửa: cút me dị ứng vl\n",
            "Câu gốc: dit me dị ứng vl\n",
            "Câu sai: cit me dị ứng vl\n",
            "\n",
            "\n",
            "\n",
            "SAI\n",
            "Từ sai: mkl \t Từ gốc: ['vkl']\n",
            "Câu sửa: mk\n",
            "Câu gốc: vkl\n",
            "Câu sai: mkl\n",
            "\n",
            "\n",
            "\n",
            "SAI\n",
            "Từ sai: dz \t Từ gốc: ['di']\n",
            "Câu sửa: phạm quyết chiến im me dm\n",
            "Câu gốc: phạm quyết chiến im me di\n",
            "Câu sai: phạm quyết chiến im me dz\n",
            "\n",
            "\n",
            "\n",
            "SAI\n",
            "Từ sai: dmk \t Từ gốc: ['đm']\n",
            "Câu sửa: dm buồn ói vl\n",
            "Câu gốc: đm buồn ói vl\n",
            "Câu sai: dmk buồn ói vl\n",
            "\n",
            "\n",
            "\n",
            "SAI\n",
            "Từ sai: mạy \t Từ gốc: ['mày']\n",
            "Câu sửa: lừa đc mình xong chặn cmn bố theo chúng may thông báo cho mn biết hết lừa luôn đã có khách hàng khách đã tin tưởng sử dụng sim\n",
            "Câu gốc: lừa đc mình xong chặn cmnl bố theo chúng mày thông báo cho mn biết hết lừa luôn  đã có khách hàng khách đã tin tưởng sử dụng sim\n",
            "Câu sai: lừa đc mình xong chặn cmnl bố theo chúng mạy thông báo cho mn biết hết lừa luôn đã có khách hàng khách đã tin tưởng sử dụng sim\n",
            "\n",
            "\n",
            "\n",
            "SAI\n",
            "Từ sai: đmmm \t Từ gốc: ['đm']\n",
            "Câu sửa: đmm cờ rep pi vl\n",
            "Câu gốc: đm cờ rép pi vl\n",
            "Câu sai: đmmm cờ rép pi vl\n",
            "\n",
            "\n",
            "\n",
            "SAI\n",
            "Từ sai: nj \t Từ gốc: ['ng']\n",
            "Câu sửa: đây đe đc la fan cư na\n",
            "Câu gốc: đây đe đc la fan cư ng\n",
            "Câu sai: đây đe đc la fan cư nj\n",
            "\n",
            "\n",
            "\n",
            "SAI\n",
            "Từ sai: màý \t Từ gốc: ['mày']\n",
            "Câu sửa: mà khôn lắm thằng ngu\n",
            "Câu gốc: mày khôn lắm thằng ngu\n",
            "Câu sai: màý khôn lắm thằng ngu\n",
            "\n",
            "\n",
            "\n",
            "SAI\n",
            "Từ sai: phịc \t Từ gốc: ['chịch']\n",
            "Câu sửa: là để làm ji là che cho quan ăn cướp phúc dạo chớ mình chả đc ji mất nhà mất xe cộ chỉ vì cái gọi là lol\n",
            "Câu gốc: là để làm ji là che cho quan ăn cướp chịch dạo chớ mềnh chả đc ji mất nhà mất xe cộ chỉ vì cái gọi là lol \n",
            "Câu sai: là để làm ji là che cho quan ăn cướp phịc dạo chớ mềnh chả đc ji mất nhà mất xe cộ chỉ vì cái gọi là lol\n",
            "\n",
            "\n",
            "\n",
            "SAI\n",
            "Từ sai: ol \t Từ gốc: ['vl']\n",
            "Câu sửa: đôi cánh gà hoá quỷ nể cặp này lo\n",
            "Câu gốc: đôi cánh gà hoá quỷ nể cặp này vl\n",
            "Câu sai: đôi cánh gà hoá quỷ nể cặp này ol\n",
            "\n",
            "\n",
            "\n",
            "SAI\n",
            "Từ sai: đmmm \t Từ gốc: ['đm']\n",
            "Câu sửa: đmm phải bán dm giống tân vl\n",
            "Câu gốc: đm phải bán dm giống tân vl\n",
            "Câu sai: đmmm phải bán dm giống tân vl\n",
            "\n",
            "\n",
            "\n",
            "SAI\n",
            "Từ sai: vq \t Từ gốc: ['vl']\n",
            "Câu sửa: mình nhớ nc và\n",
            "Câu gốc: mình nhớ nyc vl\n",
            "Câu sai: mình nhớ nyc vq\n",
            "\n",
            "\n",
            "\n",
            "SAI\n",
            "Từ sai: jl \t Từ gốc: ['vl']\n",
            "Câu sửa: đâu anh nư ng cl\n",
            "Câu gốc: đâu anh nư ng vl\n",
            "Câu sai: đâu anh nư ng jl\n",
            "\n",
            "\n",
            "\n",
            "SAI\n",
            "Từ sai: vlm \t Từ gốc: ['vl']\n",
            "Câu sửa: dkm gr này lắm trẩu clm\n",
            "Câu gốc: dkm gr này lắm trẩu vl\n",
            "Câu sai: dkm gr này lắm trẩu vlm\n",
            "\n",
            "\n",
            "\n",
            "SAI\n",
            "Từ sai: dmcm \t Từ gốc: ['đcm']\n",
            "Câu sửa: nhi nhi dcm nhây vcl\n",
            "Câu gốc: nhii nhii đcm nhây vcl\n",
            "Câu sai: nhii nhii dmcm nhây vcl\n",
            "\n",
            "\n",
            "\n",
            "SAI\n",
            "SÓT\n",
            "Từ sai: kjhùng \t Từ gốc: ['khùng']\n",
            "Câu sửa: kjhùng\n",
            "Câu gốc: khùng\n",
            "Câu sai: kjhùng\n",
            "\n",
            "\n",
            "\n",
            "SAI\n",
            "SÓT\n",
            "Từ sai: haãm \t Từ gốc: ['hãm']\n",
            "Câu sửa: haãm vcl\n",
            "Câu gốc: hãm vcl\n",
            "Câu sai: haãm vcl\n",
            "\n",
            "\n",
            "\n",
            "SAI\n",
            "Từ sai: vnl \t Từ gốc: ['vl']\n",
            "Câu sửa: đi mẹ làm bố bố vkl\n",
            "Câu gốc: đizzz mẹ làm bố bễ vl\n",
            "Câu sai: đizzz mẹ làm bố bễ vnl\n",
            "\n",
            "\n",
            "\n",
            "SAI\n",
            "Từ sai: đmmm \t Từ gốc: ['đm']\n",
            "Câu sửa: đmm nhìn ngứa vl\n",
            "Câu gốc: đm nhìn ngứa vl\n",
            "Câu sai: đmmm nhìn ngứa vl\n",
            "\n",
            "\n",
            "\n",
            "SAI\n",
            "Từ sai: hwt \t Từ gốc: ['hút']\n",
            "Câu sửa: lỗ hết cỏ siêu nhân đỏ\n",
            "Câu gốc: lỗ hút cỏ siêu nhân đỏ\n",
            "Câu sai: lỗ hwt cỏ siêu nhân đỏ\n",
            "\n",
            "\n",
            "\n",
            "SAI\n",
            "Từ sai: nàk \t Từ gốc: ['này']\n",
            "Câu sửa: giải nào cơ cấu lạ lòn vl\n",
            "Câu gốc: giải này cơ cấu lạ lòn vl\n",
            "Câu sai: giải nàk cơ cấu lạ lòn vl\n",
            "\n",
            "\n",
            "\n",
            "SAI\n",
            "Từ sai: dmk \t Từ gốc: ['đm']\n",
            "Câu sửa: uyên hoàng hoi xoá dkm hung dữ vl\n",
            "Câu gốc: uyên hoàng hoi xoá đm hung dữ vl\n",
            "Câu sai: uyên hoàng hoi xoá dmk hung dữ vl\n",
            "\n",
            "\n",
            "\n",
            "SAI\n",
            "Từ sai: đmmm \t Từ gốc: ['đm']\n",
            "Câu sửa: từ cân lên cân đmm vl\n",
            "Câu gốc: từ cân lên cân đm vl\n",
            "Câu sai: từ cân lên cân đmmm vl\n",
            "\n",
            "\n",
            "\n",
            "SAI\n",
            "Từ sai: vdl \t Từ gốc: ['vl']\n",
            "Câu sửa: nguyễn văn quyền dm bình luận hay vcl\n",
            "Câu gốc: nguyễn văn quyền dm bình luận hay vl\n",
            "Câu sai: nguyễn văn quyền dm bình luận hay vdl\n",
            "\n",
            "\n",
            "\n",
            "SAI\n",
            "Từ sai: yl \t Từ gốc: ['vl']\n",
            "Câu sửa: muốn giết ny nó ly\n",
            "Câu gốc: muốn giết ny nó vl\n",
            "Câu sai: muốn giết ny nó yl\n",
            "\n",
            "\n",
            "\n",
            "SAI\n",
            "Từ sai: dmk \t Từ gốc: ['đm']\n",
            "Câu sửa: dm sợ vl\n",
            "Câu gốc: đm sợ vl\n",
            "Câu sai: dmk sợ vl\n",
            "\n",
            "\n",
            "\n",
            "SAI\n",
            "Từ sai: đmmm \t Từ gốc: ['đm']\n",
            "Câu sửa: linh louisa đmm hung hăng vl\n",
            "Câu gốc: linh louisa đm hung hăng vl\n",
            "Câu sai: linh louisa đmmm hung hăng vl\n",
            "\n",
            "\n",
            "\n",
            "SAI\n",
            "Từ sai: đmmm \t Từ gốc: ['đm']\n",
            "Câu sửa: đmm tao thề tao thổi như vậy phi pham d post bombsquad\n",
            "Câu gốc: đm tao thề tao thổi như vậy phi pham d post  bombsquad\n",
            "Câu sai: đmmm tao thề tao thổi như vậy phi pham d post bombsquad\n",
            "\n",
            "\n",
            "\n",
            "SAI\n",
            "Từ sai: đme \t Từ gốc: ['đm']\n",
            "Câu sửa: đmm nút fan cứng oai vl\n",
            "Câu gốc: đme nút fan cứng oai vl\n",
            "Câu sai: đme nút fan cứng oai vl\n",
            "\n",
            "\n",
            "\n",
            "SAI\n",
            "SÓT\n",
            "Từ sai: tẽm \t Từ gốc: ['tởm']\n",
            "Câu sửa: lz tẽm mày\n",
            "Câu gốc: lz tởm moày\n",
            "Câu sai: lz tẽm moày\n",
            "\n",
            "\n",
            "\n",
            "SAI\n",
            "Từ sai: fm \t Từ gốc: ['em']\n",
            "Câu sửa: bé đm vl lên dc fan cứng sẽ nhác cmt kk\n",
            "Câu gốc: bé em vl lên dc fan cứng sẽ nhác cmt kkk\n",
            "Câu sai: bé fm vl lên dc fan cứng sẽ nhác cmt kkk\n",
            "\n",
            "\n",
            "\n",
            "SAI\n",
            "Từ sai: dmk \t Từ gốc: ['đm']\n",
            "Câu sửa: nếu thua tao xin hứa bao giờ đi bay lắc nữa dm xin chưa xin hứa\n",
            "Câu gốc: nếu thua tao xin hứa bao giờ đi bay lắc nữa đm xin hưa xin hứa\n",
            "Câu sai: nếu thua tao xin hứa bao giờ đi bay lắc nữa dmk xin hưa xin hứa\n",
            "\n",
            "\n",
            "\n",
            "SAI\n",
            "Từ sai: phịc \t Từ gốc: ['chịch']\n",
            "Câu sửa: lý mạnh mặn thèm phúc vl\n",
            "Câu gốc: lý mạnh  mặn thèm chịch vl\n",
            "Câu sai: lý mạnh mặn thèm phịc vl\n",
            "\n",
            "\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2-NSteCvA9Bn",
        "outputId": "1edf1ed8-2d39-4cdc-8215-271f548adfb8"
      },
      "source": [
        "# open('/content/drive/MyDrive/Colab Notebooks/KLTN_hatespeech/log_result/hate_offensive/fasttextvne_kdn.txt', 'w').write(s)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "95399"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 45
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_tABGzqLAXmP",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f85ba724-fc32-4683-f68d-3c9bf7c60cd6"
      },
      "source": [
        "print('SL đúng:', dung)\n",
        "print('SL sai :', sai)\n",
        "print('SL sót :', sot)\n",
        "print('Acc    :', dung*100/(dung+sai), '%')\n",
        "print('TL sót :', sot*100/(dung+sai), '%')\n",
        "print('TL phát hiện     :', 100 - sot*100/(dung+sai), '%')\n",
        "print('TL đúng/phát hiện:', dung*100/(dung+sai-sot), '%')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "SL đúng: 245\n",
            "SL sai : 111\n",
            "SL sót : 11\n",
            "Acc    : 68.82022471910112 %\n",
            "TL sót : 3.0898876404494384 %\n",
            "TL phát hiện     : 96.91011235955057 %\n",
            "TL đúng/phát hiện: 71.01449275362319 %\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IpBfyfGbwiX1"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YffMfuKNZH1K"
      },
      "source": [
        "# 3. Sửa lỗi chính tả cho tập dữ liệu clean gốc"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UnhqcbEWZkun"
      },
      "source": [
        "import pickle\n",
        "def load(path):\n",
        "  return pickle.load(open(path, 'rb'))\n",
        "\n",
        "train_x = load('/content/drive/My Drive/Colab Notebooks/dump_hatespeech/test_x.dump')\n",
        "train_y = load('/content/drive/My Drive/Colab Notebooks/dump_hatespeech/test_y.dump')\n",
        "\n",
        "clean = []\n",
        "# hate_offensive = []\n",
        "train_x = list(train_x)\n",
        "for i in range(len(train_y)):\n",
        "  if train_y[i,0] == 1:\n",
        "    clean.append(train_x[i].replace('_', ' '))\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-nVloBIlYVDE",
        "outputId": "653520ce-ed23-4225-83eb-050f12d8c02e"
      },
      "source": [
        "# open('/content/drive/MyDrive/Colab Notebooks/KLTN_hatespeech/clean_test/clean_test.txt', 'w').write('\\n'.join(clean))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "355944"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 164
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_uZ4dtcrncVS"
      },
      "source": [
        "clean_cmts = clean"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "p6sew8ZlZkuo"
      },
      "source": [
        "# open('/content/drive/MyDrive/Colab Notebooks/KLTN_hatespeech/clean_test/gg_input.txt', 'w').write('\\n'.join(wrong_clean_cmts))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2nqDcXydZkup",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "dc28ec9a-46ea-468a-efec-d75a960f93ce"
      },
      "source": [
        "# !pip install -U symspellpy\n",
        "# import pkg_resources\n",
        "# from symspellpy import SymSpell, Verbosity\n",
        "\n",
        "# sym_spell = SymSpell(max_dictionary_edit_distance=2, prefix_length=7)\n",
        "# # dictionary_path = pkg_resources.resource_filename(\n",
        "# #     \"symspellpy\", \"frequency_dictionary_en_82_765.txt\")\n",
        "# # bigram_path = pkg_resources.resource_filename(\n",
        "# #     \"symspellpy\", \"frequency_bigramdictionary_en_243_342.txt\")\n",
        "# # term_index is the column of the term and count_index is the\n",
        "# # column of the term frequency\n",
        "# sym_spell.load_dictionary('/content/drive/MyDrive/Colab Notebooks/KLTN_hatespeech/SymSpell/monogram.txt', term_index=0, count_index=1)\n",
        "# sym_spell.load_bigram_dictionary('/content/drive/MyDrive/Colab Notebooks/KLTN_hatespeech/SymSpell/bigram.txt', term_index=0, count_index=2)\n",
        "\n",
        "# # lookup suggestions for multi-word input strings (supports compound\n",
        "# # splitting & merging)\n",
        "# # input_term = (\"lũ chó này tụi màyy biết tao là ai không\")\n",
        "# correct_wrong_sents = []\n",
        "# for i in clean_cmts:\n",
        "#   # max edit distance per lookup (per single word, not per whole input string)\n",
        "#   suggestions = sym_spell.lookup_compound(i, max_edit_distance=2)\n",
        "#   correct_wrong_sents.append(suggestions[0].term)\n",
        "# # # display suggestion term, edit distance, and term frequency\n",
        "# # for suggestion in suggestions:\n",
        "# #     print(suggestion.term)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting symspellpy\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/99/af/e71fcca6a42b6a63f518b0c1627e1f67822815cb0cf71e6af05acbd75c78/symspellpy-6.7.0-py3-none-any.whl (2.6MB)\n",
            "\u001b[K     |████████████████████████████████| 2.6MB 7.7MB/s \n",
            "\u001b[?25hRequirement already satisfied, skipping upgrade: numpy>=1.13.1 in /usr/local/lib/python3.6/dist-packages (from symspellpy) (1.19.4)\n",
            "Installing collected packages: symspellpy\n",
            "Successfully installed symspellpy-6.7.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Go6931WdZkup"
      },
      "source": [
        "import sys\n",
        "sys.path.append('/content/drive/My Drive/Colab Notebooks/MaliciousSpellingCorrection - Copy')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IicAphd2Zkup",
        "outputId": "9151f0d5-177d-4a69-99ab-18b381bfe618"
      },
      "source": [
        "!pip install pyxDamerauLevenshtein\n",
        "!pip install unidecode"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting pyxDamerauLevenshtein\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/6d/3f/5f9448c147bc5c3d789ef0a02177ae86c4cbd1d395fe11f81361df0d5003/pyxDamerauLevenshtein-1.6.1.tar.gz (55kB)\n",
            "\r\u001b[K     |██████                          | 10kB 21.5MB/s eta 0:00:01\r\u001b[K     |███████████▉                    | 20kB 18.4MB/s eta 0:00:01\r\u001b[K     |█████████████████▉              | 30kB 11.8MB/s eta 0:00:01\r\u001b[K     |███████████████████████▊        | 40kB 13.6MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████▊  | 51kB 15.9MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 61kB 4.9MB/s \n",
            "\u001b[?25h  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "    Preparing wheel metadata ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: numpy>=1.16.1 in /usr/local/lib/python3.6/dist-packages (from pyxDamerauLevenshtein) (1.19.4)\n",
            "Building wheels for collected packages: pyxDamerauLevenshtein\n",
            "  Building wheel for pyxDamerauLevenshtein (PEP 517) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for pyxDamerauLevenshtein: filename=pyxDamerauLevenshtein-1.6.1-cp36-cp36m-linux_x86_64.whl size=85765 sha256=6222f52c8f37993e26dccfa3ecb7dcee895ba9f90f0cf2f53c581c790089d30f\n",
            "  Stored in directory: /root/.cache/pip/wheels/d2/05/c3/989929774aa6f86a368f18f132bcc79ed7cb1ea65763c1dc09\n",
            "Successfully built pyxDamerauLevenshtein\n",
            "Installing collected packages: pyxDamerauLevenshtein\n",
            "Successfully installed pyxDamerauLevenshtein-1.6.1\n",
            "Collecting unidecode\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/74/65/91eab655041e9e92f948cb7302e54962035762ce7b518272ed9d6b269e93/Unidecode-1.1.2-py2.py3-none-any.whl (239kB)\n",
            "\u001b[K     |████████████████████████████████| 245kB 12.0MB/s \n",
            "\u001b[?25hInstalling collected packages: unidecode\n",
            "Successfully installed unidecode-1.1.2\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "x395-SmsZkup"
      },
      "source": [
        "from spelling_checking_nonBW import spelling_checking"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6cyru_G2Zkup"
      },
      "source": [
        "small_corpus_dir = '/content/drive/My Drive/Colab Notebooks/KLTN_hatespeech/small_corpus1.txt'\n",
        "badwords_dir = '/content/drive/My Drive/Colab Notebooks/KLTN_hatespeech/hate_offensive_vocab.txt'\n",
        "spelling_checking = spelling_checking(\"/content/drive/My Drive/Colab Notebooks/KLTN_hatespeech/Model/skip-gram/\", \"vocab.txt\", \"vec.npy\", small_corpus_dir, badwords_dir, CAND_LIMIT=8 )"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pQ2zB5dfZkup",
        "outputId": "c65e7b78-84c1-4b47-b288-42ce797795d8"
      },
      "source": [
        "spelling_checking.readData()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Done loading vocabulary.\n",
            "Done loading vectors.\n",
            "Corpus length          13509\n",
            "Small corpus length    2069\n",
            "Badwords length        1002\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UomOxSpjZkup",
        "outputId": "dc64c775-0d2a-4b63-f902-b84dc5b82376"
      },
      "source": [
        "# test thử 1 câu\n",
        "error_sent_list = [\"đến mấy con nguuu bị lừa quay ra chê đàn ông\"]\n",
        "revised_sent_seq, algo_corrections, cand_corrections = spelling_checking.generateAlgoCandCorrection(error_sent_list, 2)\n",
        "print(\"revised sent seq:\")\n",
        "print(revised_sent_seq)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "stage 1\n",
            "done stage 1: raw check on edit distance\n",
            "stage 2.\n",
            "done stage 2: context-dependent check.\n",
            "revised sent seq:\n",
            "[['đến', 'mấy', 'con', 'ngu', 'bị', 'lừa', 'quay', 'ra', 'chê', 'đàn', 'ông']]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_GjMJJBFZkup",
        "outputId": "fce2b838-bf28-47a6-c732-a60da84dffb9"
      },
      "source": [
        "import re \n",
        "!pip install pyvi\n",
        "from pyvi import ViTokenizer\n",
        "def processing_data(sent_list):\n",
        "  sent_list = list(sent_list)\n",
        "  temp = []\n",
        "  for index, i in enumerate(sent_list):\n",
        "    i = re.sub(r\"(.)\\1{2,}\", r\"\\1\\1\", i)\n",
        "    i = re.sub('\\x01', '', i)\n",
        "    i = re.sub('_|\\s+', ' ', i)\n",
        "    i = re.sub(\"\"\"\\!|\\\"|\\#|\\$|\\%|\\&|\\||\\'|\\(|\\)|\\*|\\+|\\,|\\-|\\.|\\/|\\:|\\;|\\<|\\=|\\>|\\?|\\@|\\[|\\\\|\\]|\\^|\\_|\\`|\\{|\\||\\}|\\~\"\"\", '', i)\n",
        "    # i = i.replace('.','')\n",
        "    # i = ViTokenizer.tokenize(i)\n",
        "    sent_list[index] = i\n",
        "  return sent_list"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: pyvi in /usr/local/lib/python3.6/dist-packages (0.1)\n",
            "Requirement already satisfied: sklearn-crfsuite in /usr/local/lib/python3.6/dist-packages (from pyvi) (0.3.6)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.6/dist-packages (from pyvi) (0.22.2.post1)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from sklearn-crfsuite->pyvi) (1.15.0)\n",
            "Requirement already satisfied: tabulate in /usr/local/lib/python3.6/dist-packages (from sklearn-crfsuite->pyvi) (0.8.7)\n",
            "Requirement already satisfied: tqdm>=2.0 in /usr/local/lib/python3.6/dist-packages (from sklearn-crfsuite->pyvi) (4.41.1)\n",
            "Requirement already satisfied: python-crfsuite>=0.8.3 in /usr/local/lib/python3.6/dist-packages (from sklearn-crfsuite->pyvi) (0.9.7)\n",
            "Requirement already satisfied: scipy>=0.17.0 in /usr/local/lib/python3.6/dist-packages (from scikit-learn->pyvi) (1.4.1)\n",
            "Requirement already satisfied: joblib>=0.11 in /usr/local/lib/python3.6/dist-packages (from scikit-learn->pyvi) (1.0.0)\n",
            "Requirement already satisfied: numpy>=1.11.0 in /usr/local/lib/python3.6/dist-packages (from scikit-learn->pyvi) (1.19.4)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MG7TmbORZkup"
      },
      "source": [
        "# def loaikitudau(word):\n",
        "#   return word[0] + re.sub('w|s|f|r|x|j', '', word[1:])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Pz-08w3MZkup"
      },
      "source": [
        "wrong_sents = processing_data(clean_cmts)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NJpvLoJwZkup"
      },
      "source": [
        "# for i in range(len(wrong_sents)):\n",
        "#   wrong_sents[i] = loaikitudau(wrong_sents[i])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qn1PzrArZkup",
        "outputId": "63a9b926-f0ea-48ab-94fb-e8d9a107f77f"
      },
      "source": [
        "# sửa cho tập train và lưu xuống\n",
        "correct_wrong_sents,_,_ = spelling_checking.generateAlgoCandCorrection(wrong_sents,2)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "stage 1\n",
            "done stage 1: raw check on edit distance\n",
            "stage 2.\n",
            "done stage 2: context-dependent check.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "e5QauqDxZkup"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nLEnAbn_Zkup"
      },
      "source": [
        "temp = []\n",
        "for i in correct_wrong_sents:\n",
        "  temp.append(' '.join(i))\n",
        "correct_wrong_sents = temp"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LJet9xG5Zkup"
      },
      "source": [
        "badwords = open('/content/drive/MyDrive/Colab Notebooks/KLTN_hatespeech/SuaLoiChinhTa/badwords.txt').read().split('\\n')\n",
        "for i in range(len(badwords)):\n",
        "  badwords[i] = badwords[i].split()[0]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "agYMA3JxNU8l"
      },
      "source": [
        "# correct_wrong_sents = open('/content/drive/MyDrive/Colab Notebooks/KLTN_hatespeech/clean_test/clean_test_gg.txt').read().split('\\n')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BMkl5U9qagye"
      },
      "source": [
        "def badword_len(sent, badwords):\n",
        "  sent = sent.split()\n",
        "  num = 0\n",
        "  bw = []\n",
        "  for i in badwords:\n",
        "    if i in sent:\n",
        "      num += 1\n",
        "      bw.append(i)\n",
        "  return num, bw"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mTuJ4sO4Zkup"
      },
      "source": [
        "badword_sent_num = 0\n",
        "mt_sent_num = 0\n",
        "s = ''\n",
        "for i in range(len(clean_cmts)):\n",
        "  n1, bw1 = badword_len(clean_cmts[i], badwords)\n",
        "  n2, bw2 = badword_len(correct_wrong_sents[i], badwords)\n",
        "  if len(set(bw2) - set(bw1)) != 0:\n",
        "    badword_sent_num +=1\n",
        "    s = s + 'THÊM\\n'\n",
        "  else:\n",
        "    s = s + 'KHÔNG\\n'\n",
        "  s = s + 'Thêm Badword: ' + str(set(bw2) - set(bw1)) + '\\n'\n",
        "  s = s + 'Từ bị sửa:    ' + str(set(clean_cmts[i].split()) -set(correct_wrong_sents[i].split())) + '\\n'\n",
        "  s = s + 'Câu gốc:      ' + str(clean_cmts[i]) + '\\n'\n",
        "  s = s + 'Câu sửa:      ' + str(correct_wrong_sents[i]) + '\\n'\n",
        "  s = s + '-----------------------\\n\\n'\n",
        "  # print('Thêm Badword: ', set(bw2) - set(bw1))\n",
        "  # print('Từ bị sửa:    ', set(clean_cmts[i].split()) -set(correct_wrong_sents[i].split()))\n",
        "  # print('Câu gốc:      ', clean_cmts[i])\n",
        "  # print('Câu sửa:      ', correct_wrong_sents[i])\n",
        "  # print('-----------------------\\n\\n')\n",
        "\n",
        "  if len(set(clean_cmts[i].split()) -set(correct_wrong_sents[i].split())) != 0:\n",
        "    mt_sent_num += 1"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rpY7LNaqZkuq",
        "outputId": "78dfcde2-0dca-4eba-e619-ed015cb3758b"
      },
      "source": [
        "print('SL câu có thêm từ badword:     ', badword_sent_num)\n",
        "print('TL câu có thêm từ badword:     ', badword_sent_num*100/len(clean_cmts), '%')\n",
        "print('SL câu có từ thay đổi:         ', mt_sent_num)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "SL câu có thêm từ badword:      142\n",
            "TL câu có thêm từ badword:      3.824400754107191 %\n",
            "SL câu có từ thay đổi:          1744\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Dxm9zExXvy6V",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "794bb01f-fabc-423d-c1b7-8f39527e7da6"
      },
      "source": [
        "open('/content/drive/MyDrive/Colab Notebooks/KLTN_hatespeech/log_result/clean_goc/fasttext_vne.txt', 'w').write(s)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "1085426"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 64
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FrEHVnXKcZkw"
      },
      "source": [
        "# 4. Tạo tập test trên tất cả các badword cho công cụ sửa lỗi chính tả"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rPEh9iZLcZkx"
      },
      "source": [
        "Tạo tập badword"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nnZcNNdxcZky"
      },
      "source": [
        "import pickle\n",
        "def load(path):\n",
        "  return pickle.load(open(path, 'rb'))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OZWX7GgbcZkz"
      },
      "source": [
        "train_x = load('/content/drive/My Drive/Colab Notebooks/dump_hatespeech/train_x.dump')\n",
        "train_y = load('/content/drive/My Drive/Colab Notebooks/dump_hatespeech/train_y.dump')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yOgMmEPxcZkz"
      },
      "source": [
        "clean = []\n",
        "hate_offensive = []\n",
        "train_x = list(train_x)\n",
        "for i in range(len(train_y)):\n",
        "  if train_y[i,0] == 1:\n",
        "    clean.append(train_x[i].replace('_', ' '))\n",
        "  else:\n",
        "    hate_offensive.append(train_x[i].replace('_', ' '))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XaWrkZGbcZkz",
        "outputId": "84a00203-bf76-4973-bdb7-b85c43063595"
      },
      "source": [
        "print(\"clean lenght                \", len(clean))\n",
        "print(\"hate and offensive lenght   \", len(hate_offensive))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "clean lenght                 14901\n",
            "hate and offensive lenght    1375\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "d-RJv1_vcZk0"
      },
      "source": [
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "vectorizer = CountVectorizer(min_df=8).fit(clean+hate_offensive*4)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3jr4aj8OcZk1"
      },
      "source": [
        "clean_vec = vectorizer.transform(clean).toarray()\n",
        "hate_offensive_vec = vectorizer.transform(hate_offensive).toarray()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "f4Qv5CUAcZk1"
      },
      "source": [
        "import numpy as np\n",
        "clean_vec = np.sum(clean_vec, axis=0)\n",
        "hate_offensive_vec = np.sum(hate_offensive_vec, axis=0)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oHDn-oe4cZk1",
        "outputId": "f37d1f07-d0fa-4260-bc88-d78a4861137f"
      },
      "source": [
        "clean_vec"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([13,  9,  6, ..., 19, 10, 79])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PkauMOtwcZk1",
        "outputId": "5cceb9e6-e2d3-4c08-dcfb-b36bde1d683f"
      },
      "source": [
        "hate_offensive_vec"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([0, 0, 1, ..., 0, 3, 1])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MFggLqudcZk2"
      },
      "source": [
        "sub = np.subtract(hate_offensive_vec, clean_vec)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-e_ilVvccZk2"
      },
      "source": [
        "feature = vectorizer.get_feature_names()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "y8tdkL3hcZk2",
        "outputId": "ae6ca3e8-a74d-4618-a90e-f8a7c58d0c16"
      },
      "source": [
        "badwords = []\n",
        "for i in range(len(sub)):\n",
        "  if sub[i] > 2:\n",
        "    badwords.append(feature[i])\n",
        "print(\"badwords lenght\", len(badwords))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "badwords lenght 62\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ik-FSW1UcZk2"
      },
      "source": [
        "Thống kê tần suất của các từ badword và sort chúng lại"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "idBalgylcZk3"
      },
      "source": [
        "from collections import Counter"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "F6_Z4LYJcZk3"
      },
      "source": [
        "count = Counter((' '.join(hate_offensive)).split())"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "285ECyXjcZk3"
      },
      "source": [
        "temp = dict()\n",
        "for i in badwords:\n",
        "  temp[i] = count[i]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2CGJcunicZk3"
      },
      "source": [
        "badwords = temp"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JmF8HPUMcZk3"
      },
      "source": [
        "badwords = sorted(badwords.items(), key=lambda x: x[1], reverse=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rYksyPfucZk4"
      },
      "source": [
        "s = ''\n",
        "badwords = dict(badwords)\n",
        "for i in badwords:\n",
        "  s = s + i + ' ' + str(badwords[i]) + '\\n'\n",
        "s = s[:-1]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GHLUqSudcZk4",
        "outputId": "c4612ba7-a71a-43c9-d95d-d02810489a3f"
      },
      "source": [
        "open('/content/drive/My Drive/Colab Notebooks/KLTN_hatespeech/SuaLoiChinhTa/badwords.txt', 'w').write(s)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "421"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uHYEEIkGcZk4"
      },
      "source": [
        "Đọc tập dữ liệu thực tế và tìm các lỗi chính tả của các từ badword"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "q8arI6SIcZk4"
      },
      "source": [
        "thin_data = open('/content/drive/My Drive/Colab Notebooks/BadWord/data_processed.txt').read().replace('\\n', ' ')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "W-vNTF17cZk4"
      },
      "source": [
        "thin_count = Counter(thin_data.split())"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "v9AtQ1FQcZk5"
      },
      "source": [
        "misspell = dict()\n",
        "for i in thin_count:\n",
        "  if thin_count[i] < 5:\n",
        "    misspell[i] = thin_count[i]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BG3LzUj_cZk5",
        "outputId": "b0b917b6-0a09-4660-e27f-782d6b7ecda8"
      },
      "source": [
        "!pip install editdistance\n",
        "from editdistance import eval as dist\n",
        "misspell_badwords = []\n",
        "for i in badwords:\n",
        "  temp = dict()\n",
        "  for j in misspell:\n",
        "    if dist(i, j) <= 2:\n",
        "      temp[j] = thin_count[j]\n",
        "      temp = sorted(temp.items(), key=lambda x: x[1], reverse=True)\n",
        "      temp = dict(temp)\n",
        "  misspell_badwords.append(temp)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: editdistance in /usr/local/lib/python3.6/dist-packages (0.5.3)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "d28JF5RscZk5",
        "outputId": "d086f134-bea1-4469-9c34-4c718b580304"
      },
      "source": [
        "s = ''\n",
        "for i in range(len(badwords)):\n",
        "  try:\n",
        "    s = s + list(badwords)[i] + '\\t' + ' '.join(misspell_badwords[i]) + '\\n'\n",
        "  except:\n",
        "    s = s + list(badwords)[i] + '\\n'\n",
        "s = s[:-1]\n",
        "open('/content/drive/My Drive/Colab Notebooks/KLTN_hatespeech/SuaLoiChinhTa/auto_misspell_badwords.txt','w').write(s)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "285974"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 119
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ofWKrUK8cZk6"
      },
      "source": [
        "Check lại tập badword sai chính tả đã chỉnh sửa thủ công"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Kp55feYbcZk6"
      },
      "source": [
        "mb_edited = open('/content/drive/My Drive/Colab Notebooks/KLTN_hatespeech/SuaLoiChinhTa/misspell_badwords_edited.txt').read().split('\\n')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vQ-CinrScZk6"
      },
      "source": [
        "vocab = open('/content/drive/My Drive/Colab Notebooks/KLTN_hatespeech/vocab.txt').read().split('\\n')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2OutlrLXcZk7"
      },
      "source": [
        "badwords = []\n",
        "misspells = []\n",
        "all_misspells = []\n",
        "for i in mb_edited:\n",
        "  bw, mss = i.strip().split('\\t')\n",
        "  temp = mss.split(' ')\n",
        "  mss = []\n",
        "  for j in temp:\n",
        "    if j not in vocab:\n",
        "      mss.append(j)\n",
        "  badwords.append(bw)\n",
        "  misspells.append(mss)\n",
        "  all_misspells += mss"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5tHuLSzScZk7"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VlxYKxBEcZk7"
      },
      "source": [
        "Tạo lỗi chính tả cho tập test"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eTMO7a6lcZk7"
      },
      "source": [
        "import pandas as pd\n",
        "orig_hate      = pd.read_csv('/content/drive/My Drive/Colab Notebooks/KLTN_hatespeech/hate_and_offensive_orig_test/orig_hate.csv')\n",
        "orig_offensive = pd.read_csv('/content/drive/My Drive/Colab Notebooks/KLTN_hatespeech/hate_and_offensive_orig_test/orig_offensive.csv')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RmAyecyjcZk7"
      },
      "source": [
        "def read_static(path):\n",
        "  data = open(path).read().split('\\n')\n",
        "  result = dict()\n",
        "  for i in data:\n",
        "    try:\n",
        "      word, freq = i.split()\n",
        "      freq = int(freq)\n",
        "      if freq >2:\n",
        "        result[word] = freq\n",
        "    except:\n",
        "      None\n",
        "  return result \n",
        "\n",
        "hate_word_static      = read_static('/content/drive/My Drive/Colab Notebooks/KLTN_hatespeech/temp/word_statistics/hate_words.txt')\n",
        "offensive_word_static = read_static('/content/drive/My Drive/Colab Notebooks/KLTN_hatespeech/temp/word_statistics/offensive_words.txt')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Hb45lr5wcZk7",
        "outputId": "3df624cb-2c53-4ea8-ee01-b94fda5fa098"
      },
      "source": [
        "hate_offensive_cmts = list(orig_hate['comment']) + list(orig_offensive['comment'])\n",
        "print('hate comment lenght       ', len(list(orig_hate['comment'])))\n",
        "print('offensive comment lenght  ', len(list(orig_offensive['comment'])))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "hate comment lenght        152\n",
            "offensive comment lenght   204\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lDC7vDhocZk8"
      },
      "source": [
        "import string\n",
        "import random\n",
        "def change_a_word_dis1(word):\n",
        "    Alphabet_List = list(string.ascii_lowercase)\n",
        "    # Alphabet_List.append(' ')\n",
        "    \n",
        "    # 0 - add\n",
        "    # 1 - delete\n",
        "    # 2 - change    \n",
        "    if len(word) <4:\n",
        "      method = random.choice([0,2])\n",
        "    else:\n",
        "      method = random.randint(0, 2)\n",
        "    \n",
        "    if (method==0):\n",
        "        pos = random.randint(0, len(word))\n",
        "        word1 = word[0:pos]\n",
        "        word2 = word[pos:len(word)]\n",
        "        add = Alphabet_List[random.randint(0, len(Alphabet_List)-1)]\n",
        "        return word1+add+word2\n",
        "        \n",
        "    elif (method==1):\n",
        "        pos = random.randint(0, len(word)-1)\n",
        "        word1 = word[0:pos]\n",
        "        word2 = word[pos+1:len(word)]\n",
        "        return word1+word2\n",
        "        \n",
        "    elif (method==2):\n",
        "        pos = random.randint(0, len(word)-1)\n",
        "        word1 = word[0:pos]\n",
        "        word2 = word[pos+1:len(word)]\n",
        "        change = word[pos]\n",
        "        while (change==word[pos]):        \n",
        "            change = Alphabet_List[random.randint(0, len(Alphabet_List)-1)]\n",
        "        return word1+change+word2\n",
        "\n",
        "def change_a_word(word):\n",
        "  if len(word) < 5:\n",
        "    return change_a_word_dis1(word)\n",
        "  else:\n",
        "    if random.choice([False, True]):\n",
        "      return change_a_word_dis1(word)\n",
        "    else:\n",
        "      return change_a_word_dis1(change_a_word_dis1(word))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ascuciFycZk8"
      },
      "source": [
        "import random\n",
        "# tạo lỗi chính tả cho tập badword\n",
        "correct_words = []\n",
        "wrong_words   = []\n",
        "wrong_hate_offensive_cmts = []\n",
        "wrong_type = [] # 0: Lỗi thực tế, 1: Lỗi được thu thập từ bộ anh thìn, 2: Lỗi tự sinh\n",
        "n = 0\n",
        "for id, i in enumerate(hate_offensive_cmts):\n",
        "  i = i.split()\n",
        "  flag = False\n",
        "  for id2, j in enumerate(i):\n",
        "    # Nếu lỗi chính tả độc hại có sẵn trong trong bình luận\n",
        "    if j in all_misspells:\n",
        "      # tìm xem từ gốc của nó là từ nào\n",
        "      for z in range(len(misspells)):\n",
        "        if j in misspells[z]:\n",
        "          correct_words.append(badwords[z])\n",
        "          wrong_words.append(j)\n",
        "          wrong_hate_offensive_cmts.append(' '.join(i))\n",
        "          wrong_type.append(0)\n",
        "          flag = True\n",
        "          break\n",
        "    if flag:\n",
        "        break\n",
        "  if flag:\n",
        "    continue\n",
        "\n",
        "  for id2, j in enumerate(i):\n",
        "    # Nếu câu có chứa từ badword:\n",
        "    if j in badwords:\n",
        "      if flag == False:\n",
        "        index = badwords.index(j)\n",
        "        correct_words.append(badwords[index])\n",
        "        wr_w = random.choice(misspells[index])\n",
        "        wrong_words.append(wr_w)\n",
        "        i[id2] = wr_w\n",
        "        wrong_hate_offensive_cmts.append(' '.join(i))\n",
        "        wrong_type.append(1)\n",
        "        flag = True\n",
        "      else:\n",
        "        index = badwords.index(j)\n",
        "        correct_words[-1] = correct_words[-1] + '|' + badwords[index]\n",
        "        wr_w = random.choice(misspells[index])\n",
        "        wrong_words[-1] = wrong_words[-1] + '|' + wr_w\n",
        "        i[id2] = wr_w\n",
        "        wrong_hate_offensive_cmts[-1] = ' '.join(i)\n",
        "        # wrong_type.append(1)\n",
        "        # flag = True\n",
        "  if flag:\n",
        "    continue\n",
        "\n",
        "    # Nếu câu không chứa từ badword thì thêm tự động vào \n",
        "         \n",
        "  if id <152:\n",
        "    sents = dict()\n",
        "    for j in i:\n",
        "      try:\n",
        "        sents[j] = hate_word_static[j]\n",
        "      except:\n",
        "        sents[j] = 0\n",
        "    \n",
        "    sents = dict(sorted(sents.items(), key=lambda x: x[1], reverse=True))\n",
        "    for j in sents:\n",
        "      try:\n",
        "        wr_w = change_a_word(j)\n",
        "        if wr_w in vocab and len(j) >= 2:\n",
        "          continue\n",
        "        correct_words.append(j)\n",
        "        wrong_words.append(wr_w)\n",
        "        i[i.index(j)] = wr_w\n",
        "        wrong_hate_offensive_cmts.append(' '.join(i))\n",
        "        wrong_type.append(2)\n",
        "        n += 1\n",
        "        break\n",
        "      except:\n",
        "        print(' '.join(i))\n",
        "  else:\n",
        "    sents = dict()\n",
        "    for j in i:\n",
        "      try:\n",
        "        sents[j] = offensive_word_static[j]\n",
        "      except:\n",
        "        sents[j] = 0   \n",
        "\n",
        "    sents = dict(sorted(sents.items(), key=lambda x: x[1], reverse=True))\n",
        "    for j in sents:\n",
        "      try:\n",
        "        wr_w = change_a_word(j)\n",
        "        if wr_w in vocab and len(j) >= 2:\n",
        "          continue       \n",
        "        correct_words.append(j)\n",
        "        wrong_words.append(wr_w)\n",
        "        i[i.index(j)] = wr_w\n",
        "        wrong_hate_offensive_cmts.append(' '.join(i))\n",
        "        wrong_type.append(2)\n",
        "        n += 1\n",
        "        break\n",
        "      except:\n",
        "        print(' '.join(i))\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EgWVSXU4cZk9",
        "outputId": "4e9c5f76-9ff4-450b-d769-1dfa3242eeea"
      },
      "source": [
        "print('correct word length            ', len(correct_words))\n",
        "print('wrong word length              ', len(wrong_words))\n",
        "print('hate and offensive lenght      ', len(hate_offensive_cmts))\n",
        "print('wrong hate and offensive lenght', len(wrong_hate_offensive_cmts))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "correct word length             356\n",
            "wrong word length               356\n",
            "hate and offensive lenght       356\n",
            "wrong hate and offensive lenght 356\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cuzD4WFUcZk9"
      },
      "source": [
        "Ghi kết quả sau khi tạo lỗi chính tả xuống"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "j_oUBcZvcZk-"
      },
      "source": [
        "# ghi file sai chính tả xuống\n",
        "# importing pandas as pd  \n",
        "import pandas as pd  \n",
        "   \n",
        "# dictionary of lists  \n",
        "temp = {'wrong_type': wrong_type,'correct_words': correct_words, 'wrong_words': wrong_words, 'hate_offensive_cmts': hate_offensive_cmts, 'wrong_hate_offensive_cmts':wrong_hate_offensive_cmts}  \n",
        "     \n",
        "df = pd.DataFrame(temp) \n",
        "  \n",
        "# saving the dataframe \n",
        "df.to_csv('/content/drive/My Drive/Colab Notebooks/KLTN_hatespeech/SuaLoiChinhTa/Tat_ca_cac_badword_loi/sai_chinh_ta_khong_dong_nghia.csv') "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LWP-e5J7V6zq"
      },
      "source": [
        "## Sửa lỗi chính tả"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ovw2cLrUWDsA"
      },
      "source": [
        "import pandas as pd  \n",
        "data = pd.read_csv('/content/drive/My Drive/Colab Notebooks/KLTN_hatespeech/SuaLoiChinhTa/Tat_ca_cac_badword_loi/sai_chinh_ta_khong_dong_nghia.csv')\n",
        "correct_words = data['correct_words']\n",
        "wrong_words   = data['wrong_words']\n",
        "hate_offensive_cmts = data['hate_offensive_cmts']\n",
        "wrong_hate_offensive_cmts = data['wrong_hate_offensive_cmts']\n",
        "\n",
        "correct_words = list(correct_words)\n",
        "for i in range(len(correct_words)):\n",
        "  correct_words[i] = correct_words[i]\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wT0GHpOHWDsA"
      },
      "source": [
        "# correct_wrong_sents = open('/content/drive/MyDrive/Colab Notebooks/KLTN_hatespeech/SuaLoiChinhTa/gg_output.txt').read().split('\\n')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EnHbb2TBWDsC",
        "outputId": "f76bea0e-dfca-4d12-baf1-7e67e65b31d3"
      },
      "source": [
        "# thống kê loại lỗi\n",
        "print('Real error                      ', len(data[data['wrong_type'] == 0]))\n",
        "print('Error create by Thin Dataset    ', len(data[data['wrong_type'] == 1]))\n",
        "print('Generate error                  ', len(data[data['wrong_type'] == 2]))\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Real error                       1\n",
            "Error create by Thin Dataset     307\n",
            "Generate error                   48\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tUSJ7jSAWDsC"
      },
      "source": [
        "import sys\n",
        "sys.path.append('/content/drive/My Drive/Colab Notebooks/MaliciousSpellingCorrection - Copy')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8TA1WuK1WDsD",
        "outputId": "e0f0f33a-c05e-4d9e-d161-b167e20152d9"
      },
      "source": [
        "!pip install pyxDamerauLevenshtein\n",
        "!pip install unidecode"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: pyxDamerauLevenshtein in /usr/local/lib/python3.6/dist-packages (1.6.1)\n",
            "Requirement already satisfied: numpy>=1.16.1 in /usr/local/lib/python3.6/dist-packages (from pyxDamerauLevenshtein) (1.19.4)\n",
            "Requirement already satisfied: unidecode in /usr/local/lib/python3.6/dist-packages (1.1.2)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KYol_SHLiFUI",
        "outputId": "2f670d62-be35-4431-8e33-209a25417582"
      },
      "source": [
        "method = ['skip-gram', 'cbow', 'fasttext_fb', 'fasttext_vne']\r\n",
        "for m in method:\r\n",
        "  from spelling_checking import spelling_checking\r\n",
        "  small_corpus_dir = '/content/drive/My Drive/Colab Notebooks/KLTN_hatespeech/small_corpus1.txt'\r\n",
        "  badwords_dir = '/content/drive/My Drive/Colab Notebooks/KLTN_hatespeech/hate_offensive_vocab.txt'\r\n",
        "  spelling_checking = spelling_checking(\"/content/drive/My Drive/Colab Notebooks/KLTN_hatespeech/Model/\"+m+\"/\", \"vocab.txt\", \"vec.npy\", small_corpus_dir, badwords_dir, CAND_LIMIT=8 )\r\n",
        "  spelling_checking.readData()\r\n",
        "  wrong_sents = processing_data(wrong_hate_offensive_cmts)\r\n",
        "  # sửa cho tập train và lưu xuống\r\n",
        "  correct_wrong_sents,_,_ = spelling_checking.generateAlgoCandCorrection(wrong_sents,4)\r\n",
        "\r\n",
        "  temp = []\r\n",
        "  for i in correct_wrong_sents:\r\n",
        "    temp.append(' '.join(i))\r\n",
        "  correct_wrong_sents = temp\r\n",
        "\r\n",
        "  dung = 0\r\n",
        "  sai = 0\r\n",
        "  sot = 0\r\n",
        "  s = ''\r\n",
        "  for index, i in enumerate(correct_wrong_sents):\r\n",
        "    i = i.split()\r\n",
        "    # if correct_words[index] in i:\r\n",
        "    cws = correct_words[index].split('|')\r\n",
        "    wws = wrong_words[index].split('|')\r\n",
        "    for j in range(len(cws)):\r\n",
        "      if cws[j] in set(i):\r\n",
        "        dung +=1\r\n",
        "      else:\r\n",
        "        sai += 1\r\n",
        "        s = s + 'SAI'\r\n",
        "        if wws[j] in i:\r\n",
        "          sot += 1 \r\n",
        "  print(\"\\n\\n=================================\")\r\n",
        "  print(\"METHOD:  \", m.upper())\r\n",
        "  print('SL đúng:', dung)\r\n",
        "  print('SL sai :', sai)\r\n",
        "  print('SL sót :', sot)\r\n",
        "  print('Acc    :', dung*100/(dung+sai), '%')\r\n",
        "  print('TL sót :', sot*100/(dung+sai), '%')\r\n",
        "  print('TL phát hiện     :', 100 - sot*100/(dung+sai), '%')\r\n",
        "  print('TL đúng/phát hiện:', dung*100/(dung+sai-sot), '%')\r\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Done loading vocabulary.\n",
            "Done loading vectors.\n",
            "Corpus length          13509\n",
            "Small corpus length    2069\n",
            "Badwords length        1002\n",
            "stage 1\n",
            "done stage 1: raw check on edit distance\n",
            "stage 2.\n",
            "done stage 2: context-dependent check.\n",
            "\n",
            "\n",
            "=================================\n",
            "METHOD:   SKIP-GRAM\n",
            "SL đúng: 534\n",
            "SL sai : 193\n",
            "SL sót : 22\n",
            "Acc    : 73.4525447042641 %\n",
            "TL sót : 3.0261348005502064 %\n",
            "TL phát hiện     : 96.97386519944979 %\n",
            "TL đúng/phát hiện: 75.74468085106383 %\n",
            "Done loading vocabulary.\n",
            "Done loading vectors.\n",
            "Corpus length          13509\n",
            "Small corpus length    2069\n",
            "Badwords length        1002\n",
            "stage 1\n",
            "done stage 1: raw check on edit distance\n",
            "stage 2.\n",
            "done stage 2: context-dependent check.\n",
            "\n",
            "\n",
            "=================================\n",
            "METHOD:   CBOW\n",
            "SL đúng: 527\n",
            "SL sai : 200\n",
            "SL sót : 37\n",
            "Acc    : 72.48968363136176 %\n",
            "TL sót : 5.089408528198074 %\n",
            "TL phát hiện     : 94.91059147180192 %\n",
            "TL đúng/phát hiện: 76.3768115942029 %\n",
            "Done loading vocabulary.\n",
            "Done loading vectors.\n",
            "Corpus length          13023\n",
            "Small corpus length    2069\n",
            "Badwords length        1002\n",
            "stage 1\n",
            "done stage 1: raw check on edit distance\n",
            "stage 2.\n",
            "done stage 2: context-dependent check.\n",
            "\n",
            "\n",
            "=================================\n",
            "METHOD:   FASTTEXT_FB\n",
            "SL đúng: 467\n",
            "SL sai : 260\n",
            "SL sót : 30\n",
            "Acc    : 64.23658872077029 %\n",
            "TL sót : 4.126547455295736 %\n",
            "TL phát hiện     : 95.87345254470426 %\n",
            "TL đúng/phát hiện: 67.00143472022955 %\n",
            "Done loading vocabulary.\n",
            "Done loading vectors.\n",
            "Corpus length          13509\n",
            "Small corpus length    2069\n",
            "Badwords length        1002\n",
            "stage 1\n",
            "done stage 1: raw check on edit distance\n",
            "stage 2.\n",
            "done stage 2: context-dependent check.\n",
            "\n",
            "\n",
            "=================================\n",
            "METHOD:   FASTTEXT_VNE\n",
            "SL đúng: 514\n",
            "SL sai : 213\n",
            "SL sót : 37\n",
            "Acc    : 70.70151306740027 %\n",
            "TL sót : 5.089408528198074 %\n",
            "TL phát hiện     : 94.91059147180192 %\n",
            "TL đúng/phát hiện: 74.4927536231884 %\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NG5gBR6wWDsE",
        "outputId": "21544fa6-9e07-4320-d1da-c8a18bd0e3b2"
      },
      "source": [
        "import re \n",
        "!pip install pyvi\n",
        "from pyvi import ViTokenizer\n",
        "def processing_data(sent_list):\n",
        "  sent_list = list(sent_list)\n",
        "  temp = []\n",
        "  for index, i in enumerate(sent_list):\n",
        "    i = re.sub(r\"(.)\\1{2,}\", r\"\\1\\1\", i)\n",
        "    i = re.sub('\\x01', '', i)\n",
        "    i = re.sub('_|\\s+', ' ', i)\n",
        "    i = re.sub(\"\"\"\\!|\\\"|\\#|\\$|\\%|\\&|\\||\\'|\\(|\\)|\\*|\\+|\\,|\\-|\\.|\\/|\\:|\\;|\\<|\\=|\\>|\\?|\\@|\\[|\\\\|\\]|\\^|\\_|\\`|\\{|\\||\\}|\\~\"\"\", '', i)\n",
        "    # i = i.replace('.','')\n",
        "    # i = ViTokenizer.tokenize(i)\n",
        "    sent_list[index] = i\n",
        "  return sent_list"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: pyvi in /usr/local/lib/python3.6/dist-packages (0.1)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.6/dist-packages (from pyvi) (0.22.2.post1)\n",
            "Requirement already satisfied: sklearn-crfsuite in /usr/local/lib/python3.6/dist-packages (from pyvi) (0.3.6)\n",
            "Requirement already satisfied: scipy>=0.17.0 in /usr/local/lib/python3.6/dist-packages (from scikit-learn->pyvi) (1.4.1)\n",
            "Requirement already satisfied: numpy>=1.11.0 in /usr/local/lib/python3.6/dist-packages (from scikit-learn->pyvi) (1.19.4)\n",
            "Requirement already satisfied: joblib>=0.11 in /usr/local/lib/python3.6/dist-packages (from scikit-learn->pyvi) (1.0.0)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from sklearn-crfsuite->pyvi) (1.15.0)\n",
            "Requirement already satisfied: tabulate in /usr/local/lib/python3.6/dist-packages (from sklearn-crfsuite->pyvi) (0.8.7)\n",
            "Requirement already satisfied: python-crfsuite>=0.8.3 in /usr/local/lib/python3.6/dist-packages (from sklearn-crfsuite->pyvi) (0.9.7)\n",
            "Requirement already satisfied: tqdm>=2.0 in /usr/local/lib/python3.6/dist-packages (from sklearn-crfsuite->pyvi) (4.41.1)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uqPDb5UolQr9"
      },
      "source": [
        "THí nghiệm với symspell"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AEPlAtqKWDsB",
        "outputId": "c5067ffd-08cd-4f38-ca78-66031b125c2e"
      },
      "source": [
        "!pip install -U symspellpy\n",
        "import pkg_resources\n",
        "from symspellpy import SymSpell, Verbosity\n",
        "\n",
        "sym_spell = SymSpell(max_dictionary_edit_distance=2, prefix_length=7)\n",
        "\n",
        "sym_spell.load_dictionary('/content/drive/MyDrive/Colab Notebooks/KLTN_hatespeech/SymSpell/monogram.txt', term_index=0, count_index=1)\n",
        "sym_spell.load_bigram_dictionary('/content/drive/MyDrive/Colab Notebooks/KLTN_hatespeech/SymSpell/bigram.txt', term_index=0, count_index=2)\n",
        "\n",
        "# lookup suggestions for multi-word input strings (supports compound\n",
        "# splitting & merging)\n",
        "# input_term = (\"lũ chó này tụi màyy biết tao là ai không\")\n",
        "correct_wrong_sents = []\n",
        "for i in wrong_hate_offensive_cmts:\n",
        "  # max edit distance per lookup (per single word, not per whole input string)\n",
        "  suggestions = sym_spell.lookup_compound(i, max_edit_distance=2)\n",
        "  correct_wrong_sents.append(suggestions[0].term)\n",
        "# # display suggestion term, edit distance, and term frequency\n",
        "# for suggestion in suggestions:\n",
        "#     print(suggestion.term)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting symspellpy\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/99/af/e71fcca6a42b6a63f518b0c1627e1f67822815cb0cf71e6af05acbd75c78/symspellpy-6.7.0-py3-none-any.whl (2.6MB)\n",
            "\u001b[K     |████████████████████████████████| 2.6MB 7.7MB/s \n",
            "\u001b[?25hRequirement already satisfied, skipping upgrade: numpy>=1.13.1 in /usr/local/lib/python3.6/dist-packages (from symspellpy) (1.19.4)\n",
            "Installing collected packages: symspellpy\n",
            "Successfully installed symspellpy-6.7.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "w7NcV32lWDsG"
      },
      "source": [
        "dung = 0\n",
        "sai = 0\n",
        "sot = 0\n",
        "s = ''\n",
        "for index, i in enumerate(correct_wrong_sents):\n",
        "  i = i.split()\n",
        "  # if correct_words[index] in i:\n",
        "  cws = correct_words[index].split('|')\n",
        "  wws = wrong_words[index].split('|')\n",
        "  for j in range(len(cws)):\n",
        "    if cws[j] in set(i):\n",
        "      dung +=1\n",
        "      # s = (s  + 'ĐÚNG\\n'\n",
        "      #         + 'Từ sai:  ' + wrong_words[index] + '\\t Từ gốc: ' +  '_'.join(correct_words[index]) + '\\n'\n",
        "      #         + 'Câu sửa: ' + correct_wrong_sents[index] + '\\n'\n",
        "      #         + 'Câu gốc: ' + hate_offensive_cmts[index] + '\\n'\n",
        "      #         + 'Câu sai: ' + wrong_hate_offensive_cmts[index] + '\\n'\n",
        "      #         + '----------------------------\\n\\n')\n",
        "    else:\n",
        "      sai += 1\n",
        "      s = s + 'SAI'\n",
        "\n",
        "      if wws[j] in i:\n",
        "        sot += 1 \n",
        "        s = s + ' SÓT'\n",
        "\n",
        "      # s = (s  + '\\n'\n",
        "      #         + 'Từ sai:  ' + wrong_words[index] + '\\t Từ gốc: ' +  '_'.join(correct_words[index]) + '\\n'\n",
        "      #         + 'Câu sửa: ' + correct_wrong_sents[index] + '\\n'\n",
        "      #         + 'Câu gốc: ' + hate_offensive_cmts[index] + '\\n'\n",
        "      #         + 'Câu sai: ' + wrong_hate_offensive_cmts[index] + '\\n'\n",
        "      #         + '----------------------------\\n\\n')\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yKqntXyiWDsG",
        "outputId": "e9e97797-c00e-429d-a916-54ecbf24cb7d"
      },
      "source": [
        "open('/content/drive/MyDrive/Colab Notebooks/KLTN_hatespeech/log_result/hate_offensive/fasttextvne_kdn.txt', 'w').write(s)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "95322"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 47
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DSFQSnVQWDsH",
        "outputId": "ab40203c-e099-4e3b-a1c4-de5e960aca71"
      },
      "source": [
        "print('SL đúng:', dung)\n",
        "print('SL sai :', sai)\n",
        "print('SL sót :', sot)\n",
        "print('Acc    :', dung*100/(dung+sai), '%')\n",
        "print('TL sót :', sot*100/(dung+sai), '%')\n",
        "print('TL phát hiện     :', 100 - sot*100/(dung+sai), '%')\n",
        "print('TL đúng/phát hiện:', dung*100/(dung+sai-sot), '%')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "SL đúng: 489\n",
            "SL sai : 238\n",
            "SL sót : 16\n",
            "Acc    : 67.2627235213205 %\n",
            "TL sót : 2.200825309491059 %\n",
            "TL phát hiện     : 97.79917469050893 %\n",
            "TL đúng/phát hiện: 68.77637130801688 %\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "t51Rv9xelYvB"
      },
      "source": [
        "Thí nghiệm với google"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9-o8cv1hWDsH",
        "outputId": "d3fbd200-dd74-4b47-f9f7-745a9afd6118"
      },
      "source": [
        "open('/content/drive/MyDrive/Colab Notebooks/KLTN_hatespeech/SuaLoiChinhTa/Tat_ca_cac_badword_loi/google.txt', 'w').write('\\n'.join(wrong_hate_offensive_cmts))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "21846"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 69
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5Qj25i2JmY2M"
      },
      "source": [
        "correct_wrong_sents = open('/content/drive/MyDrive/Colab Notebooks/KLTN_hatespeech/SuaLoiChinhTa/Tat_ca_cac_badword_loi/google_fix.txt').read().split('\\n')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ARFgWHmTmpPs",
        "outputId": "d366d052-d73d-4744-b962-1d763efed466"
      },
      "source": [
        "for index, i in enumerate(correct_wrong_sents):\r\n",
        "  i = i.split()\r\n",
        "  # if correct_words[index] in i:\r\n",
        "  cws = correct_words[index].split('|')\r\n",
        "  wws = wrong_words[index].split('|')\r\n",
        "  for j in range(len(cws)):\r\n",
        "    if cws[j] in set(i):\r\n",
        "      dung +=1\r\n",
        "    else:\r\n",
        "      sai += 1\r\n",
        "      s = s + 'SAI'\r\n",
        "      if wws[j] in i:\r\n",
        "        sot += 1 \r\n",
        "\r\n",
        "print('SL đúng:', dung)\r\n",
        "print('SL sai :', sai)\r\n",
        "print('SL sót :', sot)\r\n",
        "print('Acc    :', dung*100/(dung+sai), '%')\r\n",
        "print('TL sót :', sot*100/(dung+sai), '%')\r\n",
        "print('TL phát hiện     :', 100 - sot*100/(dung+sai), '%')\r\n",
        "print('TL đúng/phát hiện:', dung*100/(dung+sai-sot), '%')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "SL đúng: 685\n",
            "SL sai : 769\n",
            "SL sót : 465\n",
            "Acc    : 47.11141678129299 %\n",
            "TL sót : 31.980742778541952 %\n",
            "TL phát hiện     : 68.01925722145805 %\n",
            "TL đúng/phát hiện: 69.26188068756319 %\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TK9PBNRYnlSb"
      },
      "source": [
        "Đánh giá recall của phần phát hiện lỗi"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5pUwt7eUnkDS",
        "outputId": "399f78f3-59c4-409f-db22-60241741564d"
      },
      "source": [
        "method = ['skip-gram', 'cbow', 'fasttext_fb', 'fasttext_vne']\r\n",
        "for m in method:\r\n",
        "  from spelling_checking_recall import spelling_checking\r\n",
        "  small_corpus_dir = '/content/drive/My Drive/Colab Notebooks/KLTN_hatespeech/small_corpus1.txt'\r\n",
        "  badwords_dir = '/content/drive/My Drive/Colab Notebooks/KLTN_hatespeech/hate_offensive_vocab.txt'\r\n",
        "  spelling_checking = spelling_checking(\"/content/drive/My Drive/Colab Notebooks/KLTN_hatespeech/Model/\"+m+\"/\", \"vocab.txt\", \"vec.npy\", small_corpus_dir, badwords_dir, CAND_LIMIT=8 )\r\n",
        "  spelling_checking.readData()\r\n",
        "  # wrong_sents = processing_data(wrong_hate_offensive_cmts)\r\n",
        "\r\n",
        "  ws = []\r\n",
        "  w = []\r\n",
        "  c = []\r\n",
        "  for i in range(len(wrong_hate_offensive_cmts)):\r\n",
        "    t1 = correct_words[i].split('|')\r\n",
        "    t2 = wrong_words[i].split('|')\r\n",
        "    for j in range(len(t1)):\r\n",
        "      ws.append(wrong_hate_offensive_cmts[i])\r\n",
        "      w.append(t2[j])\r\n",
        "      c.append(t1[j])\r\n",
        "  # sửa cho tập train và lưu xuống\r\n",
        "  print(\"\\n\\n=================================\")\r\n",
        "  print(\"METHOD:  \", m.upper())\r\n",
        "  print(spelling_checking.generateAlgoCandCorrection(ws,c, w))\r\n",
        "\r\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Done loading vocabulary.\n",
            "Done loading vectors.\n",
            "Corpus length          13509\n",
            "Small corpus length    2069\n",
            "Badwords length        1002\n",
            "\n",
            "\n",
            "=================================\n",
            "METHOD:   SKIP-GRAM\n",
            "stage 2.\n",
            "Recall:  98.62448418156809\n",
            "Pre:     82.28730822873082\n",
            "None\n",
            "Done loading vocabulary.\n",
            "Done loading vectors.\n",
            "Corpus length          13509\n",
            "Small corpus length    2069\n",
            "Badwords length        1002\n",
            "\n",
            "\n",
            "=================================\n",
            "METHOD:   CBOW\n",
            "stage 2.\n",
            "Recall:  98.62448418156809\n",
            "Pre:     82.28730822873082\n",
            "None\n",
            "Done loading vocabulary.\n",
            "Done loading vectors.\n",
            "Corpus length          13023\n",
            "Small corpus length    2069\n",
            "Badwords length        1002\n",
            "\n",
            "\n",
            "=================================\n",
            "METHOD:   FASTTEXT_FB\n",
            "stage 2.\n",
            "Recall:  98.62448418156809\n",
            "Pre:     82.28730822873082\n",
            "None\n",
            "Done loading vocabulary.\n",
            "Done loading vectors.\n",
            "Corpus length          13509\n",
            "Small corpus length    2069\n",
            "Badwords length        1002\n",
            "\n",
            "\n",
            "=================================\n",
            "METHOD:   FASTTEXT_VNE\n",
            "stage 2.\n",
            "Recall:  98.62448418156809\n",
            "Pre:     82.28730822873082\n",
            "None\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "buXkkonMrbIU",
        "outputId": "db939b21-0050-46b5-879a-80b14505350a"
      },
      "source": [
        "len(correct_words)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "356"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 90
        }
      ]
    }
  ]
}